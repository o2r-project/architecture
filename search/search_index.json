{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opening Reproducible Research System Architecture \u00b6 1. Introduction and Goals \u00b6 Preamble \u00b6 The packaging of research workflows is based on the concept of the Executable Research Compendium (ERC, see specification and article ). The reproducibility service is defined by a web API specification and demonstrated in a reference implementation . Both are published under permissive open licenses, as is this document. The normative specification is given in the Markdown formatted files in the project repository , which form the basis for readable PDF and HTML versions of the architecture. A HTML and PDF version of this document are available at https://o2r.info/architecture/ and https://o2r.info/architecture/o2r-architecture.pdf respectively. 1.1 Requirements Overview \u00b6 This architecture describes the relationship of a reproducibility service with other services from the context of scientific collaboration, publishing, and preservation. Together these services can be combined into a new system for transparent and reproducible scholarly publications. The reproducibility service must provide a reliable way to create and inspect packages of computational research to support reproducible publications. Creation comprises uploading of a researcher's workspace with code, data, and documentation for building a reproducible runtime environment. This runtime environment forms the basis for inspection , i.e. discovering, examining details, and manipulating workflows on an online platform. 1.2 Quality Goals \u00b6 Transparency The system must be transparent to allow a scrutiny demanded by a rigorous scientific process. All software components must be Free and Open Source Software ( FOSS ). All text and specification must be available under a permissive public copyright license . Separation of concern The system must integrate with existing services and focus on the core functionality: creating interactive reproducible runtime environments for scientific workflows. It must not replicate existing functionality such as storage or persistent identification. Flexibility & modularity In regard to the research project setting, the system components must be well separated, so functions can be developed independently, e.g. using different programming languages. This allows different developers to contribute efficiently. It must be possible to provide various computational configurations required by specific ERC which are outside of the included runtime. 1.3 Stakeholders \u00b6 Role/Name Goal/point of contact Required interaction Author (scientist) publish ERC as part of a scientific publication process - Reviewer (scientist) examine ERC during a review process - Co-author (scientist) contribute to ERC during research (e.g. cloud based) - Reader (scientist) view and interact with ERC on a journal website - Publisher increase quality of publications in journals with ERC - Curator/preservationist ensure research is complete and archivable using ERC - Operator provide infrastructure to researchers at my university to collaborate and conduct high-quality research using ERC - Developer use and extend the tools around ERC - Some of the stakeholders are accompanied by user scenarios in prose. 2. Architecture constraints \u00b6 This section shows constraints on this project given by involved parties or conscious decisions made to ensure the longevity and transparency of the architecture and its implementations. If applicable, a motivation for constraints is given. (based on biking2 ) 2.1 Technical constraints \u00b6 Constraint Background and/or motivation TECH.1 Only open licenses All third party software or used data must be available under a suitable code license, i.e. either OSI-approved or ODC license . TECH.2 OS independent development and deployment Server applications must run in well defined Docker containers to allow installation on any host system and to not limit developers to a specific language or environment. TECH.3 Do not store secure information The team members experience and available resources do not allow for handling information with security concerns, so no critical data, such as user passwords but also data with privacy concerns, must be stored in the system. TECH.4 Configurations for ERC runtimes ERCs include the runtime environment in form of a binary archive. The architecture must support executing this runtime environment and must be able to provide different configurations outside it, for example computer architectures or operating system kernels . The minimum requirements for the containerisation solution regarding architecture and kernel apply. 2.2 Organizational constraints \u00b6 Constraint Background and/or motivation ORG.1 Team and schedule https://o2r.info/about ORG.2 Do not interfere with existing well-established peer-review process This software is not going to change how scientific publishing works, nor should it. While intentioned to support public peer-reviews, open science etc., the software should be agnostic of these aspects. ORG.3 Only open licenses All created software must be available under an OSI-approved license, documentation and specification under a CC license . ORG.4 Version control/management Code must be versioned using git and published on GitHub . ORG.5 Acknowledge transfer from group domain to persistent domain The ERC bundles artifacts coming from a private or group domain for a transfer to a public and persistent domain (cf. Curation Domain Model (in German)), which imposes requirements on the incorporated metadata. 2.3 Conventions \u00b6 Constraint Background and/or motivation CONV.1 Provide formal architecture documentation Based on arc42 (template version 7.0). CONV.2 Follow coding conventions Typical project layout and coding conventions of the respective used language should be followed as far as possible. However, we explicitly accept the research project context and do not provide full tests suites or documentation beyond what is needed by project team members. CONV.3 Documentation language is British English International research project must be understandable by anyone interested; consistency increases readability. CONV.4 Use subjectivisation for server component names Server-side components are named using personalized verbs or (ideally) professions: muncher , loader , transporter . All git repositories for software use an o2r- prefix, in case of server-side components e.g. o2r-shipper . CONV.5 Configuration using environment variables Server-side components must be configurable using all caps environment variables prefixed with the component name, e.g. SHIPPER_THE_SETTING , for required settings. Other settings should be put in a settings file suitable for the used language, e.g. config.js or config.yml . 3. System scope and context \u00b6 3.1 Business context \u00b6 Communication partner Exchanged data Technology/protocol Reproducibility service , e.g. o2r reference implementation publication platforms utilize creation and examination services for ERC; reproducibility service uses different supporting services to retrieve software artifacts, store runtime environment images, execute workflows, and save complete ERC HTTP APIs Publishing platform , e.g. online journal website or review system users access ERC status and metadata via search results and paper landing pages; review process integrates ERC details and supports manipulation; system's API using HTTP with JSON payload Collaboration platform provide means to collaboratively work on data, code, or text; such platforms support both public and private (shared) digital workspaces HTTP ID provider retrieve unique user IDs, user metadata, and authentication tokens; user must log in with the provider HTTP Execution infrastructure ERC can be executed using a shared/distributed infrastructure HTTP Data repository the reproducibility service fetches (a) content for ERC creation, or (b) complete ERC, from different sources; it stores created ERC persistently at suitable repositories, which in turn may connect to long-term archives and preservation systems HTTP , FTP , WebDAV , git Registry (metadata) the reproducibility service can deliver metadata on published ERC to registries/catalogues/search portals directly and mediately via data repositories; the service can also retrieve/harvest contextual metadata during ERC creation to reduce required user inputs; users discover ERC via registries (proprietary) HTTP APIs, persistent identifiers ( DOI ), OAI-PMH Software repository software repository provide software artifacts during ERC creation and store executable runtime environments HTTP APIs Archives and digital preservation systems saving ERCs in preservation systems includes extended data and metadata management (cf. private/group domain vs. persistent domain in the Curation Domain Model (in German)), because a different kind of access and re-use is of concern for these systems; these concerns are relevant in so far as the intermediary data repositories must be supported, but further aspects, e.g. long-term access rights, are only mediately relevant for the reproducibility service metadata in JSON and XML provided as part of HTTP requests or as files within payloads 3.2 Technical context \u00b6 All components use HTTP(S) over cable networks connections for communication (metadata documents, ERC, Linux containers, etc.). 4. Solution strategy \u00b6 This section provides a short overview of architecture decisions and for some the reasoning behind them. Web API \u00b6 The developed solution is set in an existing system of services, and first and foremost must integrate well with these systems, focussing on the specific missing features of building and running ERCs. These features are provided via a well-defined RESTful API . Microservices \u00b6 To allow a dynamic development and support the large variety of skills, all server-side features are developed in independent microservices . These microservices handle only specific functional parts of the API and allow independent development and deployment cycles. Core components are developed using server-side JavaScript based on Node.js with Express while other components are implemented in Python. We accept this diversification increases complexity of both development and testing environments and the deployment of said services. Required documentation is minimal. The typical structure should follow common practices of the respective language and tools. Storage and intra-service communication \u00b6 In accordance with the system scope, there is no reliable storage solution implemented. The microservices simply share a common pointer to a local file system path. Storage of ERC is only implemented to make the solution independent during development and for the needs of core functionality (temporal storage), but it is not a feature the solution will eventually provide. The unifying component of the architecture is the database . It is known to all microservices. Some microservices communicate via an eventing mechanism for real-time updates, such as the search database and the component providing live updates to the user via WebSockets. The eventing is based on the operation log of the database (which is normally used to synchronise database nodes). This is a clear misuse of an internal feature , but a lot simpler than maintaining a full-blown eventing solution. Demonstration, user data & authentication \u00b6 To be able to demonstrate the system, a browser-based client application is developed. It uses the RESTful API to control the system. OAuth 2.0 is used for authentication and minimal information, which is already public, is stored for each user. This information is shared between all services which require authentication via the database. The client application manages the control flow of all user interactions. Tools \u00b6 If standalone tools are developed, they provide a command-line interface (CLI). The CLI allows integration into microservices when needed and to package tools including their dependencies as containers and distributing them using a container registry. These 2nd level containers are started by the microservices and can run either next to the microservices or in an independent container cluster, providing scalability. It must only be ensured they are correctly configured in each microservice. The only required documentation is the installation into a container and usage of the CLI. 5. Building block view \u00b6 5.1 Refinement Level 1 \u00b6 5.1.1 Blackbox Publication Platforms \u00b6 Publications platforms are the online interaction points of users with scientific works. Users create publications, e.g. submitting to a scientific journal, publishing on a pre-print server, publishing on a self-hosted website, or collaborating in online repositories. Users examine publications, e.g. browsing, searching, reading, downloading, or reviewing. 5.1.2 Blackbox ID Provider \u00b6 Identification information of distributed systems is crucial, and for security reasons as well as for limiting manual reproduction of metadata, a central service can provide all of unique identification of users and metadata on users , authentication of users, and metadata on a user's works , e.g. publications or ERC. Persistent identifiers for artifacts in the reproducibility service itself are not required , as these are provided by data storage and registries. However, services such as ePIC could allow to retrieve persistent IDs. 5.1.3 Blackbox Execution Infrastructure \u00b6 The execution infrastructure provides CPU time and temporary result storage space for execution of ERC, both \"as is\" and with manipulation, i.e. changed parameters. It also provides different architectures and operating system kernel configurations which are outside of the scope of ERC's runtime environments based on containers. 5.1.4 Blackbox Data Repositories \u00b6 Data repositories are all services storing data but not software. More specifically, they may store software \"as data\", but not with software-specific features such as code versioning or installation binaries for different computer architectures. Data repositories may be self-hosted or public/free, domain-specific or generic. They typically provide persistent identifiers or handles, e.g. a DOI or URN . They are used both for loading created ERC and for storing the ERC created by the reproducibility service. 5.1.5 Blackbox Registries \u00b6 Registries are metadata indexes or catalogues. They are recipients of metadata exports by the reproducibility service to share information about ERC, e.g. add a new ERC to an author's profile. This requires the reproducibility services to translate the internal metadata model into the recipients data model and encoding. They are sources of metadata during ERC creation when the information in the fetched content is used to query registries for additional information which can be offered to the user. 5.1.6 Blackbox Software Repositories \u00b6 Software repositories are a source and a sink for software at different abstraction levels. They are a source for software dependencies, such as system packages for installing a library. They are a sink for executable images, which comprise a number of software artifacts and their dependencies, for a specific ERC instance. 5.2 Refinement Level 2 \u00b6 5.2.1 Whitebox Publication Platforms \u00b6 Publication platforms can be roughly divided into two groups. They can be either specific journals hosted independently, such as JStatSoft or JOSS , or a larger platform provided by a publisher to multiple journals, such as ScienceDirect , MDPI , SpringerLink , or PLOS . To some extend, pre-print servers, for example OSF or arXiv.org , can also fall into the latter category. Integration with the reproducibility service can happen via plug-ins to generic software, e.g. OJS , or by bespoke extensions. Integrations are based on the service's public API. 5.2.2 Whitebox ID Provider \u00b6 The reproducibility service uses ORCID to authenticate users and retrieve user metadata. The reproducibility service does not use the ORCID authorisation to edit ORCID user data or retrieve non-public data from ORCID, thus this process is pseudo-authentication using OAuth . Internally, the user's public ORCID is the main identifier. User have different levels, which allow different actions, such as \"registered user\" or \"administrator\". These levels are stored in the reproducibility service. 5.2.3 Whitebox Execution Infrastructure \u00b6 Such an infrastructure could be either self-hosted, e.g. Docker Swarm -based, use a cloud service provider, such as Amazon EC2 , Docker Cloud , or even use continuous integration services such as Travis CI or Gitlab CI . Or it could use a combination of these. Not all of these options provide the flexibility to provide configurations outside of containers, for example specific operating system kernels. An implementing system must manage these independently, for example by mapping ERC requirements like an operating system, to a part of the execution infrastructure that supports it. 5.2.4 Whitebox Data Repositories \u00b6 The reproducibility service does not persistently store anything . It only keeps copies of files during creation and inspection. So where are ERCs saved and where is their data coming from? Collaboration platforms , e.g. ownCloud/Sciebo , GitHub , ShareLatex , OSF , allow users to create, store, and share their research (code, text, data, et cetera). Besides being an interaction platform for users, they can also be seen simply as a data repository. The reproducibility service fetches contents for building an ERC from them based on public links, e.g. a public GitHub repository or shared Sciebo folder. It is possible to link ERC creation to an project/repository under development on a collaboration platform as to trigger an ERC (re-)creation or execution when changes are made. Protocols: WebDAV , ownCloud , HTTP (including webhooks ), git Domain data repositories , e.g. PANGAEA or GFZ Data Services , can be accessed by the reproducibility service during creation and execution of ERC to download data. Allowing access to data repositories reduces data duplication but requires control over/trust in the respective repository. Protocol: HTTP APIs Generic Repositories , e.g. Zenodo , Mendeley Data , Figshare , OSF , provide (a) access to complete ERC stored in repositories for inspection and execution by the reproducibility service, and (b) storage of created ERC. repositories. Protocols: (authenticated) HTTP APIs Archives and digital preservation solutions can provide long-term preservation of ERC. The data repository and/or one of the involved platform providers are responsible for preservation. A data repository might save the hosted content to an archive, be regularly harvested by an archive, or be part of a distributed dark archive, e.g. CLOCKSS . A platform provider might supply a digital preservation service, e.g. an installation of Archivematica . Protocol: HTTP carrying bitstreams and metadata Data Curation Continuum The Data Curation Continuum (cf. diagram by Andre Treloar ), describes how data moves from the private domain of a researcher to the public domain of data repositories over the course of conducting research. It describes the properties of data and important aspects of the transitions. In a publishing process based on the reproducibility service, the full migration process is run through. 5.2.5 Whitebox Registries \u00b6 Research data registries and websites, for example ( CRIS , DataCite , Google Scholar , Scopus , Altmetric , to name just a few, collect metadata on publications and provide services with this data. Services comprise discovery but also derivation of citation data and creating networks of researchers and publications. The listed examples include open platforms, commercial solutions, and institution-specific platforms. Some of the registries offer a public, well-defined API to retrieve structured metadata and to create new records. Protocol: HTTP APIs 5.2.6 Whitebox Software Repositories \u00b6 5.2.6.1 Blackbox Package repositories \u00b6 Package repositories are used during ERC creation to download and install software artifacts for specific operating systems, e.g. Debian APT or Ubuntu Launchpad , for specific programming languages or environments, e.g. CRAN , or from source, e.g. GitHub . 5.2.6.2 Blackbox Container registries \u00b6 Container registries such as Docker Hub , Quay , self-hosted Docker Registry 2.0 or Amazon ERC , store executable images of runtime environments. They can be used to distribute the runtime environments across the execution infrastructure and provide an intermediate ephemeral storage for the reproducibility service. 5.2.7 Whitebox Reproducibility Service \u00b6 5.2.7.1 Blackbox Webserver \u00b6 A webserver handles all incoming calls to the API ( /api/v1/ ) via HTTPS ( HTTP is redirected) and distributes them to the respective microservice. A working nginx configuration is available in the test setup . 5.2.7.2 Blackbox UI \u00b6 The UI is a web application based on Angular JS , see o2r-platform . It connects to all microservices via their API and is served using the same webserver as the API. 5.2.7.3 Blackbox Microservices \u00b6 The reproducibility service uses a microservice architecture to separate functionality defined by the web API specification into manageable units. This allows scalability (selected microservices can be deployed as much as needed) and technology independence for each use case and developer. The microservices all access one main database and a shared file storage. 5.2.7.4 Blackbox Tools \u00b6 Some functionality is developed as standalone tools and used as such in the microservices instead of re-implementing features. These tools are integrated via their command line interface (CLI) and executed as 2nd level containers by microservices. 5.2.7.5 Blackbox Databases \u00b6 The main document database is the unifying element of the microservice architecture. All information shared between microservices or transactions between microservices are made via the database, including session state handling for authentication. A search database is used for full-text search and advanced queries. The database's operation log, normally used for synchronization between database nodes, is also used for event-driven communication between microservices, and synchronization between main document database and search index. Note This eventing \"hack\" is expected to be replaced by a proper eventing layer for productive deployments. 5.2.7.6 Blackbox Ephemeral file storage \u00b6 After loading from external sources and during creation of ERC, the files are stored in a file storage shared between the microservices. The file structure is known to each microservice and read/write operations happen as needed. 5.3 Refinement Level 3 \u00b6 5.3.1 Whitebox microservices \u00b6 Each microservice is encapsulated as a Docker container running at its own port on an internal network and only serving its respective API path. Internal communication between the webserver and the microservices is unencrypted, i.e. HTTP . Testing : the reference implementation provides instructions on running a local instance ofr the microservices and the demonstration UI. Development : the o2r-platform GitHub project contains docker-compose configurations to run all microservices, see repository file docker-compose.yml and the project's README.md for instructions. The following table describes the microservices, their endpoints, and their features. Project API path Language Description muncher /api/v1/compendium and /api/v1/job JavaScript (Node.js) core component for CRUD of compendia and jobs (ERC execution) loader /api/v1/compendium ( HTTP POST only) JavaScript (Node.js) load workspaces from repositories and collaboration platforms finder /api/v1/search JavaScript (Node.js) discovery and search, synchronizes the database with a search database (Elasticsearch) and exposes read-only search endpoints transporter ~ /data/ and ~* \\.(zip|tar|tar.gz) JavaScript (Node.js) downloads of compendia in zip or (gzipped) tar formats informer ~* \\.io JavaScript (Node.js) socket.io -based WebSockets for live updates to the UI based on database event log, e.g. job progress inspecter /api/v1/inspection R ( plumber ) allow inspection of non-text-based file formats, e.g. .Rdata substituter /api/v1/substitution JavaScript (Node.js) create new ERCs based on existing ones by substituting files manipulater under development -- provide back-end containers for interactive ERCs ERC exporting \u00b6 Project API path Language Description shipper /api/v1/shipment Python ship ERCs, including packaging, and their metadata to third party repositories and archives Authentication \u00b6 Project API path Language Description bouncer /api/v1/auth , /api/v1/user/ JavaScript (Node.js) authentication service and user management (whoami, level changing) Supporting services \u00b6 Existing software projects can be re-used for common functionality, such as gathering statistics. These supporting services run alongside the microservices in their own containers accessible via the main webservice. Project Description Piwik collect user statistics 5.3.2 Whitebox database \u00b6 Two databases are used. MongoDB document database with enabled replica-set oplog for eventing. Collections: users sessions compendia jobs shipments The MongoDB API is used by connecting microservices via suitable client packages, which are available for all required languages. Elasticsearch search index , kept in sync with the main document database by the microservice finder . The ids are mapped to support update and delete operations. The two main resources of the API are kept in separate indices due to their different structure/mappings : compendia with type compendia jobs with type jobs The search index is accessed by clients through the search endpoint provided by finder . 5.3.3 Whitebox tools \u00b6 project language description meta Python scripts for extraction, translation and validation of metadata; for details see metadata documentation containerit R generation of Dockerfiles based on R sessions and scripts Each tool's code repository includes one or more Dockerfiles , which are automatically build and published on Docker Hub. The microservices use the tool's Docker images to execute the tools instead of installing all their dependencies into the microservices. The advantages are a controlled environment for the tool usage, independent development cycles and updating of the tools, smaller independent images for the microservices, and scalability. Meta \u00b6 Meta provides a CLI for each step of the metadata processing required in the reproducibility service as shown by the following diagram. After each step the created metadata is saved as a file per model to a directory in the compendium. A detailed view of the meta tool usage in the creation process is provided in the runtime view ERC Creation . Containerit \u00b6 The containerit tool extracts required dependencies from ERC main documents and uses the information and external configuration to create a Dockerfile, which executes the full computational workflow when the container is started. Its main strategy is to analyse the session at the end of executing the full workflow. 5.3.4 Whitebox ephemeral file storage \u00b6 A host directory is mounted into every container to the location /tmp/o2r . 6. Runtime view \u00b6 The runtime view describes the interaction between the static building blocks. It cannot cover all potential cases and focusses on the following main scenarios. Scenario Purpose and overview ERC Creation The most important workflow for an author is creating an ERC from his workspace of data, code and documentation. The author can provide these resources as a direct upload, but a more comfortable process is loading the files from a collaboration platform. Three microservices are core to this scenario: loader , muncher , and shipper . ERC Inspection The most important workflow for a reviewer or reader is executing the analysis encapsulated in an ERC. The execution comprises creation of configuration files (if missing) from metadata, compiling the a display file using the actual analysis, and saving the used runtime environment. The core microservice for this scenario is muncher . 6.1 ERC Creation \u00b6 First, the user initiates a creation of a new ERC based on a workspace containing at least a viewable file (e.g. an HTML document or a plot) based on the code and instructions provided in a either a script or literate programming document ), and any other data. The loader runs a series of steps: fetching the files, checking the incoming workspace structure, extracting raw metadata from the workspace, brokering raw metadata to o2r metadata, and saving the compendium to the database. The compendium is now a non-public candidate , meaning only the uploading user or admin users can see and edit it. All metadata processing is based on the tool meta . Then the user opens the candidate compendium, reviews and completes the metadata, and saves it. Saving triggers a metadata validation in muncher . If the validation succeeds, the metadata is brokered to several output formats as files within the compendium using meta , and then re-loaded to the database for better searchability . Next, the user must start a job to add the ERC configuration and runtime environment to the workspace, which are core elements of an ERC. The ERC configuration is a file generated from the user-provided metadata (see ERC specification ). The runtime environment consists of two parts: (a) the runtime manifest, which is created by executing the workflow once in a container based on the tool containerit ; and (b) the runtime image, which is built from the runtime manifest. A user may provide the ERC configuration file and the runtime manifest with the workspace for fine-grained control; the generation steps are skipped then. Finally the user starts a shipment of the compendium to a data repository. The shipper manages this two step process. The separate \"create\" and \"publish\" steps allow checking the shipped files and avoid unintentional shipments, because a published shipment creates an non-erasable public resource. In the code The loader has two core controllers for direct upload and load from a collaboration platform. Their core chain of functions are realised as JavaScript Promises , see the code for loader and uploader respectively. The respective steps are shared between these two cases where possible, i.e. starting with the step stripSingleBasedir . 6.2 ERC Inspection \u00b6 The user initiates an inspection of an existing ERC by providing a reference such as DOI or URL. loader retrieves the compendium files, saves them locally and loads the contained metadata. Then the user can start a new job for the compendium. muncher checks the request, creates a new job in the database and returns the job ID. The user's client can use the ID to connect to the live logs provided by informer . All following steps by muncher regularly update the database, whose change events informer uses to continuously update client via WebSockets. The job starts with creating a copy of the compendium's files for the job. A copy-on-write filesystem is advantageous for this step. Then the archived runtime image is loaded from the file in the compendium into a runtime repository. This repository may be remote (either public or private, e.g. based on Docker Registry , ECR or GitLab ) or simply the local image storage. Then all files except the runtime image archive are packed so they can be send to a container runtime. The container runtime can be local (e.g. the Docker daemon), or a container orchestration such as Kubernetes . It provides log updates as a stream to muncher , which updates the database, whose changes trigger updates of the user interface via informer . When the container is finished, muncher compares the created outputs with the ones provided in the compendium and provides the result to the user. In the code The muncher has two core resources: a compendium represents an ERC, a job represents a \"run\" of an ERC, i.e. the building, running, and saving of the runtime environment including execution of the contained workflow. The core function for this is the Executor , which chains a number of steps using JavaScript Promises , see the code . The check uses the tool erc-checker . 7. Deployment View \u00b6 7.1 Test server https://o2r.uni-muenster.de \u00b6 Motivation The o2r infrastructure is driven by the research community's need for user friendly and transparent but also scalable and reliable solutions to increase computational reproducibility in the scientific publication process. To retrieve feedback from the community (public demo) and to increase software quality (controlled non-development environment), the current development state is regularly published on a test server. Quality and/or Performance Features The server is managed completely with Ansible to ensure a well-document setup. The base operating system is CentOS Linux 7. The machine has 4 cores, 8 GB RAM, and a local storage ~100 GB, and runs on a VM host. The one machine in this deployment runs the full o2r reproducibility service, i.e. all microservices and a webserver to serve the user interfaces. It also runs the databases and ancillary services, such as a web traffic statistics service. When executing a compendium, the compendium workspace is packaged in a tarball and send to the Docker daemon. This allows easy switching to remote machines, but also has a performance disadvantage. Mapping of Building Blocks to Infrastructure All building blocks run in their own Docker container using an image provided via and build on Docker Hub using a Dockerfile included in each microservice's code repository . The server is managed by the o2r team; external building blocks are managed by the respective organisation/provider. 7.2 Production (sketch) \u00b6 Note This deployment view is a sketch for a potential productive deployment and intends to point out features of the chosen architecture and expected challenges or solutions. It is not implemented at the moment! Motivation A productive system must be reliable and scalable providing a single reproducibility service API endpoint. It must also adopt the distribution and deployments of the reproducibility service's microservices. Being based on containers it naturally uses one of the powerful orchestration engines, such as Docker Swarm or Kubernetes . It can also include multiple execution infrastructures to support multiple container software versions, different architectures, kernels, GPUs, or even specialised hardware. Operators of a reproducibility service can separate themselves from other operators by offering specific hardware or versions. Quality and/or Performance Features The services are redundantly provided via separated clusters of nodes for (a) running the reproducibility service's microservices and ancillary services, (b) running the document and search databases, (c) running ERC executions. Separating the clusters allows common security protocols, e.g. the tool and execution cluster should not be able to contact arbitrary websites. The software in the data cluster can run in containers or bare metal. The clusters for app and compendia have access to a common shared file storage, a potential bottleneck. Performance of microservices can be easily scaled by adding nodes to the respective clusters. The diversity of supported ERCs can be increased by providing different architectures and kernels, and hardware. Some requirements could be met on demand using virtualisation, such as a specific operating system version. Mapping of Building Blocks to Infrastructure The o2r reproducibility service and execution infrastructures are managed by the o2r team similar to the test server. The other big building blocks, like publishing platforms or data repositories, are managed by the respective organisations. Credits \u00b6 This specification and guides are developed by the members of the project Opening Reproducible Research ( Offene Reproduzierbare Forschung ) funded by the German Research Foundation (Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 274927273 ) under grant numbers PE 1632/10-1, KR 3930/3-1, and TR 864/6-1). Opening Reproducible Research (o2r, https://o2r.info/about ) is a DFG-funded research project by Institute for Geoinformatics ( ifgi ) and University and Regional Library ( ULB ), University of M\u00fcnster, Germany. Building on recent advances in mainstream IT, o2r envisions a new architecture for storing, executing and interacting with the original analysis environment alongside the corresponding research data and manuscript. This architecture evolves around so called Executable Research Compendia (ERC) as the container for both research, review, and archival. To cite this specification please use N\u00fcst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi: 10.5281/zenodo.2203844 For a complete list of publications, posters, presentations, and software projects from th2 o2r project please visit https://o2r.info/results/ . License \u00b6 The o2r architecture specification is licensed under Creative Commons CC0 1.0 Universal License , see file LICENSE . To the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work. This work is published from: Germany. About arc42 \u00b6 arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke. Build @@VERSION@@ @ @@TIMESTAMP@@","title":"Architecture"},{"location":"#opening-reproducible-research-system-architecture","text":"","title":"Opening Reproducible Research System Architecture"},{"location":"#1-introduction-and-goals","text":"","title":"1. Introduction and Goals"},{"location":"#preamble","text":"The packaging of research workflows is based on the concept of the Executable Research Compendium (ERC, see specification and article ). The reproducibility service is defined by a web API specification and demonstrated in a reference implementation . Both are published under permissive open licenses, as is this document. The normative specification is given in the Markdown formatted files in the project repository , which form the basis for readable PDF and HTML versions of the architecture. A HTML and PDF version of this document are available at https://o2r.info/architecture/ and https://o2r.info/architecture/o2r-architecture.pdf respectively.","title":"Preamble"},{"location":"#11-requirements-overview","text":"This architecture describes the relationship of a reproducibility service with other services from the context of scientific collaboration, publishing, and preservation. Together these services can be combined into a new system for transparent and reproducible scholarly publications. The reproducibility service must provide a reliable way to create and inspect packages of computational research to support reproducible publications. Creation comprises uploading of a researcher's workspace with code, data, and documentation for building a reproducible runtime environment. This runtime environment forms the basis for inspection , i.e. discovering, examining details, and manipulating workflows on an online platform.","title":"1.1 Requirements Overview"},{"location":"#12-quality-goals","text":"Transparency The system must be transparent to allow a scrutiny demanded by a rigorous scientific process. All software components must be Free and Open Source Software ( FOSS ). All text and specification must be available under a permissive public copyright license . Separation of concern The system must integrate with existing services and focus on the core functionality: creating interactive reproducible runtime environments for scientific workflows. It must not replicate existing functionality such as storage or persistent identification. Flexibility & modularity In regard to the research project setting, the system components must be well separated, so functions can be developed independently, e.g. using different programming languages. This allows different developers to contribute efficiently. It must be possible to provide various computational configurations required by specific ERC which are outside of the included runtime.","title":"1.2 Quality Goals"},{"location":"#13-stakeholders","text":"Role/Name Goal/point of contact Required interaction Author (scientist) publish ERC as part of a scientific publication process - Reviewer (scientist) examine ERC during a review process - Co-author (scientist) contribute to ERC during research (e.g. cloud based) - Reader (scientist) view and interact with ERC on a journal website - Publisher increase quality of publications in journals with ERC - Curator/preservationist ensure research is complete and archivable using ERC - Operator provide infrastructure to researchers at my university to collaborate and conduct high-quality research using ERC - Developer use and extend the tools around ERC - Some of the stakeholders are accompanied by user scenarios in prose.","title":"1.3 Stakeholders"},{"location":"#2-architecture-constraints","text":"This section shows constraints on this project given by involved parties or conscious decisions made to ensure the longevity and transparency of the architecture and its implementations. If applicable, a motivation for constraints is given. (based on biking2 )","title":"2. Architecture constraints"},{"location":"#21-technical-constraints","text":"Constraint Background and/or motivation TECH.1 Only open licenses All third party software or used data must be available under a suitable code license, i.e. either OSI-approved or ODC license . TECH.2 OS independent development and deployment Server applications must run in well defined Docker containers to allow installation on any host system and to not limit developers to a specific language or environment. TECH.3 Do not store secure information The team members experience and available resources do not allow for handling information with security concerns, so no critical data, such as user passwords but also data with privacy concerns, must be stored in the system. TECH.4 Configurations for ERC runtimes ERCs include the runtime environment in form of a binary archive. The architecture must support executing this runtime environment and must be able to provide different configurations outside it, for example computer architectures or operating system kernels . The minimum requirements for the containerisation solution regarding architecture and kernel apply.","title":"2.1 Technical constraints"},{"location":"#22-organizational-constraints","text":"Constraint Background and/or motivation ORG.1 Team and schedule https://o2r.info/about ORG.2 Do not interfere with existing well-established peer-review process This software is not going to change how scientific publishing works, nor should it. While intentioned to support public peer-reviews, open science etc., the software should be agnostic of these aspects. ORG.3 Only open licenses All created software must be available under an OSI-approved license, documentation and specification under a CC license . ORG.4 Version control/management Code must be versioned using git and published on GitHub . ORG.5 Acknowledge transfer from group domain to persistent domain The ERC bundles artifacts coming from a private or group domain for a transfer to a public and persistent domain (cf. Curation Domain Model (in German)), which imposes requirements on the incorporated metadata.","title":"2.2 Organizational constraints"},{"location":"#23-conventions","text":"Constraint Background and/or motivation CONV.1 Provide formal architecture documentation Based on arc42 (template version 7.0). CONV.2 Follow coding conventions Typical project layout and coding conventions of the respective used language should be followed as far as possible. However, we explicitly accept the research project context and do not provide full tests suites or documentation beyond what is needed by project team members. CONV.3 Documentation language is British English International research project must be understandable by anyone interested; consistency increases readability. CONV.4 Use subjectivisation for server component names Server-side components are named using personalized verbs or (ideally) professions: muncher , loader , transporter . All git repositories for software use an o2r- prefix, in case of server-side components e.g. o2r-shipper . CONV.5 Configuration using environment variables Server-side components must be configurable using all caps environment variables prefixed with the component name, e.g. SHIPPER_THE_SETTING , for required settings. Other settings should be put in a settings file suitable for the used language, e.g. config.js or config.yml .","title":"2.3 Conventions"},{"location":"#3-system-scope-and-context","text":"","title":"3. System scope and context"},{"location":"#31-business-context","text":"Communication partner Exchanged data Technology/protocol Reproducibility service , e.g. o2r reference implementation publication platforms utilize creation and examination services for ERC; reproducibility service uses different supporting services to retrieve software artifacts, store runtime environment images, execute workflows, and save complete ERC HTTP APIs Publishing platform , e.g. online journal website or review system users access ERC status and metadata via search results and paper landing pages; review process integrates ERC details and supports manipulation; system's API using HTTP with JSON payload Collaboration platform provide means to collaboratively work on data, code, or text; such platforms support both public and private (shared) digital workspaces HTTP ID provider retrieve unique user IDs, user metadata, and authentication tokens; user must log in with the provider HTTP Execution infrastructure ERC can be executed using a shared/distributed infrastructure HTTP Data repository the reproducibility service fetches (a) content for ERC creation, or (b) complete ERC, from different sources; it stores created ERC persistently at suitable repositories, which in turn may connect to long-term archives and preservation systems HTTP , FTP , WebDAV , git Registry (metadata) the reproducibility service can deliver metadata on published ERC to registries/catalogues/search portals directly and mediately via data repositories; the service can also retrieve/harvest contextual metadata during ERC creation to reduce required user inputs; users discover ERC via registries (proprietary) HTTP APIs, persistent identifiers ( DOI ), OAI-PMH Software repository software repository provide software artifacts during ERC creation and store executable runtime environments HTTP APIs Archives and digital preservation systems saving ERCs in preservation systems includes extended data and metadata management (cf. private/group domain vs. persistent domain in the Curation Domain Model (in German)), because a different kind of access and re-use is of concern for these systems; these concerns are relevant in so far as the intermediary data repositories must be supported, but further aspects, e.g. long-term access rights, are only mediately relevant for the reproducibility service metadata in JSON and XML provided as part of HTTP requests or as files within payloads","title":"3.1 Business context"},{"location":"#32-technical-context","text":"All components use HTTP(S) over cable networks connections for communication (metadata documents, ERC, Linux containers, etc.).","title":"3.2 Technical context"},{"location":"#4-solution-strategy","text":"This section provides a short overview of architecture decisions and for some the reasoning behind them.","title":"4. Solution strategy"},{"location":"#web-api","text":"The developed solution is set in an existing system of services, and first and foremost must integrate well with these systems, focussing on the specific missing features of building and running ERCs. These features are provided via a well-defined RESTful API .","title":"Web API"},{"location":"#microservices","text":"To allow a dynamic development and support the large variety of skills, all server-side features are developed in independent microservices . These microservices handle only specific functional parts of the API and allow independent development and deployment cycles. Core components are developed using server-side JavaScript based on Node.js with Express while other components are implemented in Python. We accept this diversification increases complexity of both development and testing environments and the deployment of said services. Required documentation is minimal. The typical structure should follow common practices of the respective language and tools.","title":"Microservices"},{"location":"#storage-and-intra-service-communication","text":"In accordance with the system scope, there is no reliable storage solution implemented. The microservices simply share a common pointer to a local file system path. Storage of ERC is only implemented to make the solution independent during development and for the needs of core functionality (temporal storage), but it is not a feature the solution will eventually provide. The unifying component of the architecture is the database . It is known to all microservices. Some microservices communicate via an eventing mechanism for real-time updates, such as the search database and the component providing live updates to the user via WebSockets. The eventing is based on the operation log of the database (which is normally used to synchronise database nodes). This is a clear misuse of an internal feature , but a lot simpler than maintaining a full-blown eventing solution.","title":"Storage and intra-service communication"},{"location":"#demonstration-user-data-authentication","text":"To be able to demonstrate the system, a browser-based client application is developed. It uses the RESTful API to control the system. OAuth 2.0 is used for authentication and minimal information, which is already public, is stored for each user. This information is shared between all services which require authentication via the database. The client application manages the control flow of all user interactions.","title":"Demonstration, user data &amp; authentication"},{"location":"#tools","text":"If standalone tools are developed, they provide a command-line interface (CLI). The CLI allows integration into microservices when needed and to package tools including their dependencies as containers and distributing them using a container registry. These 2nd level containers are started by the microservices and can run either next to the microservices or in an independent container cluster, providing scalability. It must only be ensured they are correctly configured in each microservice. The only required documentation is the installation into a container and usage of the CLI.","title":"Tools"},{"location":"#5-building-block-view","text":"","title":"5. Building block view"},{"location":"#51-refinement-level-1","text":"","title":"5.1 Refinement Level 1"},{"location":"#511-blackbox-publication-platforms","text":"Publications platforms are the online interaction points of users with scientific works. Users create publications, e.g. submitting to a scientific journal, publishing on a pre-print server, publishing on a self-hosted website, or collaborating in online repositories. Users examine publications, e.g. browsing, searching, reading, downloading, or reviewing.","title":"5.1.1 Blackbox Publication Platforms"},{"location":"#512-blackbox-id-provider","text":"Identification information of distributed systems is crucial, and for security reasons as well as for limiting manual reproduction of metadata, a central service can provide all of unique identification of users and metadata on users , authentication of users, and metadata on a user's works , e.g. publications or ERC. Persistent identifiers for artifacts in the reproducibility service itself are not required , as these are provided by data storage and registries. However, services such as ePIC could allow to retrieve persistent IDs.","title":"5.1.2 Blackbox ID Provider"},{"location":"#513-blackbox-execution-infrastructure","text":"The execution infrastructure provides CPU time and temporary result storage space for execution of ERC, both \"as is\" and with manipulation, i.e. changed parameters. It also provides different architectures and operating system kernel configurations which are outside of the scope of ERC's runtime environments based on containers.","title":"5.1.3 Blackbox Execution Infrastructure"},{"location":"#514-blackbox-data-repositories","text":"Data repositories are all services storing data but not software. More specifically, they may store software \"as data\", but not with software-specific features such as code versioning or installation binaries for different computer architectures. Data repositories may be self-hosted or public/free, domain-specific or generic. They typically provide persistent identifiers or handles, e.g. a DOI or URN . They are used both for loading created ERC and for storing the ERC created by the reproducibility service.","title":"5.1.4 Blackbox Data Repositories"},{"location":"#515-blackbox-registries","text":"Registries are metadata indexes or catalogues. They are recipients of metadata exports by the reproducibility service to share information about ERC, e.g. add a new ERC to an author's profile. This requires the reproducibility services to translate the internal metadata model into the recipients data model and encoding. They are sources of metadata during ERC creation when the information in the fetched content is used to query registries for additional information which can be offered to the user.","title":"5.1.5 Blackbox Registries"},{"location":"#516-blackbox-software-repositories","text":"Software repositories are a source and a sink for software at different abstraction levels. They are a source for software dependencies, such as system packages for installing a library. They are a sink for executable images, which comprise a number of software artifacts and their dependencies, for a specific ERC instance.","title":"5.1.6 Blackbox Software Repositories"},{"location":"#52-refinement-level-2","text":"","title":"5.2 Refinement Level 2"},{"location":"#521-whitebox-publication-platforms","text":"Publication platforms can be roughly divided into two groups. They can be either specific journals hosted independently, such as JStatSoft or JOSS , or a larger platform provided by a publisher to multiple journals, such as ScienceDirect , MDPI , SpringerLink , or PLOS . To some extend, pre-print servers, for example OSF or arXiv.org , can also fall into the latter category. Integration with the reproducibility service can happen via plug-ins to generic software, e.g. OJS , or by bespoke extensions. Integrations are based on the service's public API.","title":"5.2.1 Whitebox Publication Platforms"},{"location":"#522-whitebox-id-provider","text":"The reproducibility service uses ORCID to authenticate users and retrieve user metadata. The reproducibility service does not use the ORCID authorisation to edit ORCID user data or retrieve non-public data from ORCID, thus this process is pseudo-authentication using OAuth . Internally, the user's public ORCID is the main identifier. User have different levels, which allow different actions, such as \"registered user\" or \"administrator\". These levels are stored in the reproducibility service.","title":"5.2.2 Whitebox ID Provider"},{"location":"#523-whitebox-execution-infrastructure","text":"Such an infrastructure could be either self-hosted, e.g. Docker Swarm -based, use a cloud service provider, such as Amazon EC2 , Docker Cloud , or even use continuous integration services such as Travis CI or Gitlab CI . Or it could use a combination of these. Not all of these options provide the flexibility to provide configurations outside of containers, for example specific operating system kernels. An implementing system must manage these independently, for example by mapping ERC requirements like an operating system, to a part of the execution infrastructure that supports it.","title":"5.2.3 Whitebox Execution Infrastructure"},{"location":"#524-whitebox-data-repositories","text":"The reproducibility service does not persistently store anything . It only keeps copies of files during creation and inspection. So where are ERCs saved and where is their data coming from? Collaboration platforms , e.g. ownCloud/Sciebo , GitHub , ShareLatex , OSF , allow users to create, store, and share their research (code, text, data, et cetera). Besides being an interaction platform for users, they can also be seen simply as a data repository. The reproducibility service fetches contents for building an ERC from them based on public links, e.g. a public GitHub repository or shared Sciebo folder. It is possible to link ERC creation to an project/repository under development on a collaboration platform as to trigger an ERC (re-)creation or execution when changes are made. Protocols: WebDAV , ownCloud , HTTP (including webhooks ), git Domain data repositories , e.g. PANGAEA or GFZ Data Services , can be accessed by the reproducibility service during creation and execution of ERC to download data. Allowing access to data repositories reduces data duplication but requires control over/trust in the respective repository. Protocol: HTTP APIs Generic Repositories , e.g. Zenodo , Mendeley Data , Figshare , OSF , provide (a) access to complete ERC stored in repositories for inspection and execution by the reproducibility service, and (b) storage of created ERC. repositories. Protocols: (authenticated) HTTP APIs Archives and digital preservation solutions can provide long-term preservation of ERC. The data repository and/or one of the involved platform providers are responsible for preservation. A data repository might save the hosted content to an archive, be regularly harvested by an archive, or be part of a distributed dark archive, e.g. CLOCKSS . A platform provider might supply a digital preservation service, e.g. an installation of Archivematica . Protocol: HTTP carrying bitstreams and metadata Data Curation Continuum The Data Curation Continuum (cf. diagram by Andre Treloar ), describes how data moves from the private domain of a researcher to the public domain of data repositories over the course of conducting research. It describes the properties of data and important aspects of the transitions. In a publishing process based on the reproducibility service, the full migration process is run through.","title":"5.2.4 Whitebox Data Repositories"},{"location":"#525-whitebox-registries","text":"Research data registries and websites, for example ( CRIS , DataCite , Google Scholar , Scopus , Altmetric , to name just a few, collect metadata on publications and provide services with this data. Services comprise discovery but also derivation of citation data and creating networks of researchers and publications. The listed examples include open platforms, commercial solutions, and institution-specific platforms. Some of the registries offer a public, well-defined API to retrieve structured metadata and to create new records. Protocol: HTTP APIs","title":"5.2.5 Whitebox Registries"},{"location":"#526-whitebox-software-repositories","text":"","title":"5.2.6 Whitebox Software Repositories"},{"location":"#5261-blackbox-package-repositories","text":"Package repositories are used during ERC creation to download and install software artifacts for specific operating systems, e.g. Debian APT or Ubuntu Launchpad , for specific programming languages or environments, e.g. CRAN , or from source, e.g. GitHub .","title":"5.2.6.1 Blackbox Package repositories"},{"location":"#5262-blackbox-container-registries","text":"Container registries such as Docker Hub , Quay , self-hosted Docker Registry 2.0 or Amazon ERC , store executable images of runtime environments. They can be used to distribute the runtime environments across the execution infrastructure and provide an intermediate ephemeral storage for the reproducibility service.","title":"5.2.6.2 Blackbox Container registries"},{"location":"#527-whitebox-reproducibility-service","text":"","title":"5.2.7 Whitebox Reproducibility Service"},{"location":"#5271-blackbox-webserver","text":"A webserver handles all incoming calls to the API ( /api/v1/ ) via HTTPS ( HTTP is redirected) and distributes them to the respective microservice. A working nginx configuration is available in the test setup .","title":"5.2.7.1 Blackbox Webserver"},{"location":"#5272-blackbox-ui","text":"The UI is a web application based on Angular JS , see o2r-platform . It connects to all microservices via their API and is served using the same webserver as the API.","title":"5.2.7.2 Blackbox UI"},{"location":"#5273-blackbox-microservices","text":"The reproducibility service uses a microservice architecture to separate functionality defined by the web API specification into manageable units. This allows scalability (selected microservices can be deployed as much as needed) and technology independence for each use case and developer. The microservices all access one main database and a shared file storage.","title":"5.2.7.3 Blackbox Microservices"},{"location":"#5274-blackbox-tools","text":"Some functionality is developed as standalone tools and used as such in the microservices instead of re-implementing features. These tools are integrated via their command line interface (CLI) and executed as 2nd level containers by microservices.","title":"5.2.7.4 Blackbox Tools"},{"location":"#5275-blackbox-databases","text":"The main document database is the unifying element of the microservice architecture. All information shared between microservices or transactions between microservices are made via the database, including session state handling for authentication. A search database is used for full-text search and advanced queries. The database's operation log, normally used for synchronization between database nodes, is also used for event-driven communication between microservices, and synchronization between main document database and search index. Note This eventing \"hack\" is expected to be replaced by a proper eventing layer for productive deployments.","title":"5.2.7.5 Blackbox Databases"},{"location":"#5276-blackbox-ephemeral-file-storage","text":"After loading from external sources and during creation of ERC, the files are stored in a file storage shared between the microservices. The file structure is known to each microservice and read/write operations happen as needed.","title":"5.2.7.6 Blackbox Ephemeral file storage"},{"location":"#53-refinement-level-3","text":"","title":"5.3 Refinement Level 3"},{"location":"#531-whitebox-microservices","text":"Each microservice is encapsulated as a Docker container running at its own port on an internal network and only serving its respective API path. Internal communication between the webserver and the microservices is unencrypted, i.e. HTTP . Testing : the reference implementation provides instructions on running a local instance ofr the microservices and the demonstration UI. Development : the o2r-platform GitHub project contains docker-compose configurations to run all microservices, see repository file docker-compose.yml and the project's README.md for instructions. The following table describes the microservices, their endpoints, and their features. Project API path Language Description muncher /api/v1/compendium and /api/v1/job JavaScript (Node.js) core component for CRUD of compendia and jobs (ERC execution) loader /api/v1/compendium ( HTTP POST only) JavaScript (Node.js) load workspaces from repositories and collaboration platforms finder /api/v1/search JavaScript (Node.js) discovery and search, synchronizes the database with a search database (Elasticsearch) and exposes read-only search endpoints transporter ~ /data/ and ~* \\.(zip|tar|tar.gz) JavaScript (Node.js) downloads of compendia in zip or (gzipped) tar formats informer ~* \\.io JavaScript (Node.js) socket.io -based WebSockets for live updates to the UI based on database event log, e.g. job progress inspecter /api/v1/inspection R ( plumber ) allow inspection of non-text-based file formats, e.g. .Rdata substituter /api/v1/substitution JavaScript (Node.js) create new ERCs based on existing ones by substituting files manipulater under development -- provide back-end containers for interactive ERCs","title":"5.3.1 Whitebox microservices"},{"location":"#erc-exporting","text":"Project API path Language Description shipper /api/v1/shipment Python ship ERCs, including packaging, and their metadata to third party repositories and archives","title":"ERC exporting"},{"location":"#authentication","text":"Project API path Language Description bouncer /api/v1/auth , /api/v1/user/ JavaScript (Node.js) authentication service and user management (whoami, level changing)","title":"Authentication"},{"location":"#supporting-services","text":"Existing software projects can be re-used for common functionality, such as gathering statistics. These supporting services run alongside the microservices in their own containers accessible via the main webservice. Project Description Piwik collect user statistics","title":"Supporting services"},{"location":"#532-whitebox-database","text":"Two databases are used. MongoDB document database with enabled replica-set oplog for eventing. Collections: users sessions compendia jobs shipments The MongoDB API is used by connecting microservices via suitable client packages, which are available for all required languages. Elasticsearch search index , kept in sync with the main document database by the microservice finder . The ids are mapped to support update and delete operations. The two main resources of the API are kept in separate indices due to their different structure/mappings : compendia with type compendia jobs with type jobs The search index is accessed by clients through the search endpoint provided by finder .","title":"5.3.2 Whitebox database"},{"location":"#533-whitebox-tools","text":"project language description meta Python scripts for extraction, translation and validation of metadata; for details see metadata documentation containerit R generation of Dockerfiles based on R sessions and scripts Each tool's code repository includes one or more Dockerfiles , which are automatically build and published on Docker Hub. The microservices use the tool's Docker images to execute the tools instead of installing all their dependencies into the microservices. The advantages are a controlled environment for the tool usage, independent development cycles and updating of the tools, smaller independent images for the microservices, and scalability.","title":"5.3.3 Whitebox tools"},{"location":"#meta","text":"Meta provides a CLI for each step of the metadata processing required in the reproducibility service as shown by the following diagram. After each step the created metadata is saved as a file per model to a directory in the compendium. A detailed view of the meta tool usage in the creation process is provided in the runtime view ERC Creation .","title":"Meta"},{"location":"#containerit","text":"The containerit tool extracts required dependencies from ERC main documents and uses the information and external configuration to create a Dockerfile, which executes the full computational workflow when the container is started. Its main strategy is to analyse the session at the end of executing the full workflow.","title":"Containerit"},{"location":"#534-whitebox-ephemeral-file-storage","text":"A host directory is mounted into every container to the location /tmp/o2r .","title":"5.3.4 Whitebox ephemeral file storage"},{"location":"#6-runtime-view","text":"The runtime view describes the interaction between the static building blocks. It cannot cover all potential cases and focusses on the following main scenarios. Scenario Purpose and overview ERC Creation The most important workflow for an author is creating an ERC from his workspace of data, code and documentation. The author can provide these resources as a direct upload, but a more comfortable process is loading the files from a collaboration platform. Three microservices are core to this scenario: loader , muncher , and shipper . ERC Inspection The most important workflow for a reviewer or reader is executing the analysis encapsulated in an ERC. The execution comprises creation of configuration files (if missing) from metadata, compiling the a display file using the actual analysis, and saving the used runtime environment. The core microservice for this scenario is muncher .","title":"6. Runtime view"},{"location":"#61-erc-creation","text":"First, the user initiates a creation of a new ERC based on a workspace containing at least a viewable file (e.g. an HTML document or a plot) based on the code and instructions provided in a either a script or literate programming document ), and any other data. The loader runs a series of steps: fetching the files, checking the incoming workspace structure, extracting raw metadata from the workspace, brokering raw metadata to o2r metadata, and saving the compendium to the database. The compendium is now a non-public candidate , meaning only the uploading user or admin users can see and edit it. All metadata processing is based on the tool meta . Then the user opens the candidate compendium, reviews and completes the metadata, and saves it. Saving triggers a metadata validation in muncher . If the validation succeeds, the metadata is brokered to several output formats as files within the compendium using meta , and then re-loaded to the database for better searchability . Next, the user must start a job to add the ERC configuration and runtime environment to the workspace, which are core elements of an ERC. The ERC configuration is a file generated from the user-provided metadata (see ERC specification ). The runtime environment consists of two parts: (a) the runtime manifest, which is created by executing the workflow once in a container based on the tool containerit ; and (b) the runtime image, which is built from the runtime manifest. A user may provide the ERC configuration file and the runtime manifest with the workspace for fine-grained control; the generation steps are skipped then. Finally the user starts a shipment of the compendium to a data repository. The shipper manages this two step process. The separate \"create\" and \"publish\" steps allow checking the shipped files and avoid unintentional shipments, because a published shipment creates an non-erasable public resource. In the code The loader has two core controllers for direct upload and load from a collaboration platform. Their core chain of functions are realised as JavaScript Promises , see the code for loader and uploader respectively. The respective steps are shared between these two cases where possible, i.e. starting with the step stripSingleBasedir .","title":"6.1 ERC Creation"},{"location":"#62-erc-inspection","text":"The user initiates an inspection of an existing ERC by providing a reference such as DOI or URL. loader retrieves the compendium files, saves them locally and loads the contained metadata. Then the user can start a new job for the compendium. muncher checks the request, creates a new job in the database and returns the job ID. The user's client can use the ID to connect to the live logs provided by informer . All following steps by muncher regularly update the database, whose change events informer uses to continuously update client via WebSockets. The job starts with creating a copy of the compendium's files for the job. A copy-on-write filesystem is advantageous for this step. Then the archived runtime image is loaded from the file in the compendium into a runtime repository. This repository may be remote (either public or private, e.g. based on Docker Registry , ECR or GitLab ) or simply the local image storage. Then all files except the runtime image archive are packed so they can be send to a container runtime. The container runtime can be local (e.g. the Docker daemon), or a container orchestration such as Kubernetes . It provides log updates as a stream to muncher , which updates the database, whose changes trigger updates of the user interface via informer . When the container is finished, muncher compares the created outputs with the ones provided in the compendium and provides the result to the user. In the code The muncher has two core resources: a compendium represents an ERC, a job represents a \"run\" of an ERC, i.e. the building, running, and saving of the runtime environment including execution of the contained workflow. The core function for this is the Executor , which chains a number of steps using JavaScript Promises , see the code . The check uses the tool erc-checker .","title":"6.2 ERC Inspection"},{"location":"#7-deployment-view","text":"","title":"7. Deployment View"},{"location":"#71-test-server-httpso2runi-muensterde","text":"Motivation The o2r infrastructure is driven by the research community's need for user friendly and transparent but also scalable and reliable solutions to increase computational reproducibility in the scientific publication process. To retrieve feedback from the community (public demo) and to increase software quality (controlled non-development environment), the current development state is regularly published on a test server. Quality and/or Performance Features The server is managed completely with Ansible to ensure a well-document setup. The base operating system is CentOS Linux 7. The machine has 4 cores, 8 GB RAM, and a local storage ~100 GB, and runs on a VM host. The one machine in this deployment runs the full o2r reproducibility service, i.e. all microservices and a webserver to serve the user interfaces. It also runs the databases and ancillary services, such as a web traffic statistics service. When executing a compendium, the compendium workspace is packaged in a tarball and send to the Docker daemon. This allows easy switching to remote machines, but also has a performance disadvantage. Mapping of Building Blocks to Infrastructure All building blocks run in their own Docker container using an image provided via and build on Docker Hub using a Dockerfile included in each microservice's code repository . The server is managed by the o2r team; external building blocks are managed by the respective organisation/provider.","title":"7.1 Test server https://o2r.uni-muenster.de"},{"location":"#72-production-sketch","text":"Note This deployment view is a sketch for a potential productive deployment and intends to point out features of the chosen architecture and expected challenges or solutions. It is not implemented at the moment! Motivation A productive system must be reliable and scalable providing a single reproducibility service API endpoint. It must also adopt the distribution and deployments of the reproducibility service's microservices. Being based on containers it naturally uses one of the powerful orchestration engines, such as Docker Swarm or Kubernetes . It can also include multiple execution infrastructures to support multiple container software versions, different architectures, kernels, GPUs, or even specialised hardware. Operators of a reproducibility service can separate themselves from other operators by offering specific hardware or versions. Quality and/or Performance Features The services are redundantly provided via separated clusters of nodes for (a) running the reproducibility service's microservices and ancillary services, (b) running the document and search databases, (c) running ERC executions. Separating the clusters allows common security protocols, e.g. the tool and execution cluster should not be able to contact arbitrary websites. The software in the data cluster can run in containers or bare metal. The clusters for app and compendia have access to a common shared file storage, a potential bottleneck. Performance of microservices can be easily scaled by adding nodes to the respective clusters. The diversity of supported ERCs can be increased by providing different architectures and kernels, and hardware. Some requirements could be met on demand using virtualisation, such as a specific operating system version. Mapping of Building Blocks to Infrastructure The o2r reproducibility service and execution infrastructures are managed by the o2r team similar to the test server. The other big building blocks, like publishing platforms or data repositories, are managed by the respective organisations.","title":"7.2 Production (sketch)"},{"location":"#credits","text":"This specification and guides are developed by the members of the project Opening Reproducible Research ( Offene Reproduzierbare Forschung ) funded by the German Research Foundation (Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 274927273 ) under grant numbers PE 1632/10-1, KR 3930/3-1, and TR 864/6-1). Opening Reproducible Research (o2r, https://o2r.info/about ) is a DFG-funded research project by Institute for Geoinformatics ( ifgi ) and University and Regional Library ( ULB ), University of M\u00fcnster, Germany. Building on recent advances in mainstream IT, o2r envisions a new architecture for storing, executing and interacting with the original analysis environment alongside the corresponding research data and manuscript. This architecture evolves around so called Executable Research Compendia (ERC) as the container for both research, review, and archival. To cite this specification please use N\u00fcst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi: 10.5281/zenodo.2203844 For a complete list of publications, posters, presentations, and software projects from th2 o2r project please visit https://o2r.info/results/ .","title":"Credits"},{"location":"#license","text":"The o2r architecture specification is licensed under Creative Commons CC0 1.0 Universal License , see file LICENSE . To the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work. This work is published from: Germany.","title":"License"},{"location":"#about-arc42","text":"arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke. Build @@VERSION@@ @ @@TIMESTAMP@@","title":"About arc42"},{"location":"01_introduction-and-goals/","text":"1. Introduction and Goals \u00b6 Preamble \u00b6 The packaging of research workflows is based on the concept of the Executable Research Compendium (ERC, see specification and article ). The reproducibility service is defined by a web API specification and demonstrated in a reference implementation . Both are published under permissive open licenses, as is this document. The normative specification is given in the Markdown formatted files in the project repository , which form the basis for readable PDF and HTML versions of the architecture. A HTML and PDF version of this document are available at https://o2r.info/architecture/ and https://o2r.info/architecture/o2r-architecture.pdf respectively. 1.1 Requirements Overview \u00b6 This architecture describes the relationship of a reproducibility service with other services from the context of scientific collaboration, publishing, and preservation. Together these services can be combined into a new system for transparent and reproducible scholarly publications. The reproducibility service must provide a reliable way to create and inspect packages of computational research to support reproducible publications. Creation comprises uploading of a researcher's workspace with code, data, and documentation for building a reproducible runtime environment. This runtime environment forms the basis for inspection , i.e. discovering, examining details, and manipulating workflows on an online platform. 1.2 Quality Goals \u00b6 Transparency The system must be transparent to allow a scrutiny demanded by a rigorous scientific process. All software components must be Free and Open Source Software ( FOSS ). All text and specification must be available under a permissive public copyright license . Separation of concern The system must integrate with existing services and focus on the core functionality: creating interactive reproducible runtime environments for scientific workflows. It must not replicate existing functionality such as storage or persistent identification. Flexibility & modularity In regard to the research project setting, the system components must be well separated, so functions can be developed independently, e.g. using different programming languages. This allows different developers to contribute efficiently. It must be possible to provide various computational configurations required by specific ERC which are outside of the included runtime. 1.3 Stakeholders \u00b6 Role/Name Goal/point of contact Required interaction Author (scientist) publish ERC as part of a scientific publication process - Reviewer (scientist) examine ERC during a review process - Co-author (scientist) contribute to ERC during research (e.g. cloud based) - Reader (scientist) view and interact with ERC on a journal website - Publisher increase quality of publications in journals with ERC - Curator/preservationist ensure research is complete and archivable using ERC - Operator provide infrastructure to researchers at my university to collaborate and conduct high-quality research using ERC - Developer use and extend the tools around ERC - Some of the stakeholders are accompanied by user scenarios in prose.","title":"01 introduction and goals"},{"location":"01_introduction-and-goals/#1-introduction-and-goals","text":"","title":"1. Introduction and Goals"},{"location":"01_introduction-and-goals/#preamble","text":"The packaging of research workflows is based on the concept of the Executable Research Compendium (ERC, see specification and article ). The reproducibility service is defined by a web API specification and demonstrated in a reference implementation . Both are published under permissive open licenses, as is this document. The normative specification is given in the Markdown formatted files in the project repository , which form the basis for readable PDF and HTML versions of the architecture. A HTML and PDF version of this document are available at https://o2r.info/architecture/ and https://o2r.info/architecture/o2r-architecture.pdf respectively.","title":"Preamble"},{"location":"01_introduction-and-goals/#11-requirements-overview","text":"This architecture describes the relationship of a reproducibility service with other services from the context of scientific collaboration, publishing, and preservation. Together these services can be combined into a new system for transparent and reproducible scholarly publications. The reproducibility service must provide a reliable way to create and inspect packages of computational research to support reproducible publications. Creation comprises uploading of a researcher's workspace with code, data, and documentation for building a reproducible runtime environment. This runtime environment forms the basis for inspection , i.e. discovering, examining details, and manipulating workflows on an online platform.","title":"1.1 Requirements Overview"},{"location":"01_introduction-and-goals/#12-quality-goals","text":"Transparency The system must be transparent to allow a scrutiny demanded by a rigorous scientific process. All software components must be Free and Open Source Software ( FOSS ). All text and specification must be available under a permissive public copyright license . Separation of concern The system must integrate with existing services and focus on the core functionality: creating interactive reproducible runtime environments for scientific workflows. It must not replicate existing functionality such as storage or persistent identification. Flexibility & modularity In regard to the research project setting, the system components must be well separated, so functions can be developed independently, e.g. using different programming languages. This allows different developers to contribute efficiently. It must be possible to provide various computational configurations required by specific ERC which are outside of the included runtime.","title":"1.2 Quality Goals"},{"location":"01_introduction-and-goals/#13-stakeholders","text":"Role/Name Goal/point of contact Required interaction Author (scientist) publish ERC as part of a scientific publication process - Reviewer (scientist) examine ERC during a review process - Co-author (scientist) contribute to ERC during research (e.g. cloud based) - Reader (scientist) view and interact with ERC on a journal website - Publisher increase quality of publications in journals with ERC - Curator/preservationist ensure research is complete and archivable using ERC - Operator provide infrastructure to researchers at my university to collaborate and conduct high-quality research using ERC - Developer use and extend the tools around ERC - Some of the stakeholders are accompanied by user scenarios in prose.","title":"1.3 Stakeholders"},{"location":"02_architecture-constraints/","text":"2. Architecture constraints \u00b6 This section shows constraints on this project given by involved parties or conscious decisions made to ensure the longevity and transparency of the architecture and its implementations. If applicable, a motivation for constraints is given. (based on biking2 ) 2.1 Technical constraints \u00b6 Constraint Background and/or motivation TECH.1 Only open licenses All third party software or used data must be available under a suitable code license, i.e. either OSI-approved or ODC license . TECH.2 OS independent development and deployment Server applications must run in well defined Docker containers to allow installation on any host system and to not limit developers to a specific language or environment. TECH.3 Do not store secure information The team members experience and available resources do not allow for handling information with security concerns, so no critical data, such as user passwords but also data with privacy concerns, must be stored in the system. TECH.4 Configurations for ERC runtimes ERCs include the runtime environment in form of a binary archive. The architecture must support executing this runtime environment and must be able to provide different configurations outside it, for example computer architectures or operating system kernels . The minimum requirements for the containerisation solution regarding architecture and kernel apply. 2.2 Organizational constraints \u00b6 Constraint Background and/or motivation ORG.1 Team and schedule https://o2r.info/about ORG.2 Do not interfere with existing well-established peer-review process This software is not going to change how scientific publishing works, nor should it. While intentioned to support public peer-reviews, open science etc., the software should be agnostic of these aspects. ORG.3 Only open licenses All created software must be available under an OSI-approved license, documentation and specification under a CC license . ORG.4 Version control/management Code must be versioned using git and published on GitHub . ORG.5 Acknowledge transfer from group domain to persistent domain The ERC bundles artifacts coming from a private or group domain for a transfer to a public and persistent domain (cf. Curation Domain Model (in German)), which imposes requirements on the incorporated metadata. 2.3 Conventions \u00b6 Constraint Background and/or motivation CONV.1 Provide formal architecture documentation Based on arc42 (template version 7.0). CONV.2 Follow coding conventions Typical project layout and coding conventions of the respective used language should be followed as far as possible. However, we explicitly accept the research project context and do not provide full tests suites or documentation beyond what is needed by project team members. CONV.3 Documentation language is British English International research project must be understandable by anyone interested; consistency increases readability. CONV.4 Use subjectivisation for server component names Server-side components are named using personalized verbs or (ideally) professions: muncher , loader , transporter . All git repositories for software use an o2r- prefix, in case of server-side components e.g. o2r-shipper . CONV.5 Configuration using environment variables Server-side components must be configurable using all caps environment variables prefixed with the component name, e.g. SHIPPER_THE_SETTING , for required settings. Other settings should be put in a settings file suitable for the used language, e.g. config.js or config.yml .","title":"02 architecture constraints"},{"location":"02_architecture-constraints/#2-architecture-constraints","text":"This section shows constraints on this project given by involved parties or conscious decisions made to ensure the longevity and transparency of the architecture and its implementations. If applicable, a motivation for constraints is given. (based on biking2 )","title":"2. Architecture constraints"},{"location":"02_architecture-constraints/#21-technical-constraints","text":"Constraint Background and/or motivation TECH.1 Only open licenses All third party software or used data must be available under a suitable code license, i.e. either OSI-approved or ODC license . TECH.2 OS independent development and deployment Server applications must run in well defined Docker containers to allow installation on any host system and to not limit developers to a specific language or environment. TECH.3 Do not store secure information The team members experience and available resources do not allow for handling information with security concerns, so no critical data, such as user passwords but also data with privacy concerns, must be stored in the system. TECH.4 Configurations for ERC runtimes ERCs include the runtime environment in form of a binary archive. The architecture must support executing this runtime environment and must be able to provide different configurations outside it, for example computer architectures or operating system kernels . The minimum requirements for the containerisation solution regarding architecture and kernel apply.","title":"2.1 Technical constraints"},{"location":"02_architecture-constraints/#22-organizational-constraints","text":"Constraint Background and/or motivation ORG.1 Team and schedule https://o2r.info/about ORG.2 Do not interfere with existing well-established peer-review process This software is not going to change how scientific publishing works, nor should it. While intentioned to support public peer-reviews, open science etc., the software should be agnostic of these aspects. ORG.3 Only open licenses All created software must be available under an OSI-approved license, documentation and specification under a CC license . ORG.4 Version control/management Code must be versioned using git and published on GitHub . ORG.5 Acknowledge transfer from group domain to persistent domain The ERC bundles artifacts coming from a private or group domain for a transfer to a public and persistent domain (cf. Curation Domain Model (in German)), which imposes requirements on the incorporated metadata.","title":"2.2 Organizational constraints"},{"location":"02_architecture-constraints/#23-conventions","text":"Constraint Background and/or motivation CONV.1 Provide formal architecture documentation Based on arc42 (template version 7.0). CONV.2 Follow coding conventions Typical project layout and coding conventions of the respective used language should be followed as far as possible. However, we explicitly accept the research project context and do not provide full tests suites or documentation beyond what is needed by project team members. CONV.3 Documentation language is British English International research project must be understandable by anyone interested; consistency increases readability. CONV.4 Use subjectivisation for server component names Server-side components are named using personalized verbs or (ideally) professions: muncher , loader , transporter . All git repositories for software use an o2r- prefix, in case of server-side components e.g. o2r-shipper . CONV.5 Configuration using environment variables Server-side components must be configurable using all caps environment variables prefixed with the component name, e.g. SHIPPER_THE_SETTING , for required settings. Other settings should be put in a settings file suitable for the used language, e.g. config.js or config.yml .","title":"2.3 Conventions"},{"location":"03_system-scope-and-context/","text":"3. System scope and context \u00b6 3.1 Business context \u00b6 Communication partner Exchanged data Technology/protocol Reproducibility service , e.g. o2r reference implementation publication platforms utilize creation and examination services for ERC; reproducibility service uses different supporting services to retrieve software artifacts, store runtime environment images, execute workflows, and save complete ERC HTTP APIs Publishing platform , e.g. online journal website or review system users access ERC status and metadata via search results and paper landing pages; review process integrates ERC details and supports manipulation; system's API using HTTP with JSON payload Collaboration platform provide means to collaboratively work on data, code, or text; such platforms support both public and private (shared) digital workspaces HTTP ID provider retrieve unique user IDs, user metadata, and authentication tokens; user must log in with the provider HTTP Execution infrastructure ERC can be executed using a shared/distributed infrastructure HTTP Data repository the reproducibility service fetches (a) content for ERC creation, or (b) complete ERC, from different sources; it stores created ERC persistently at suitable repositories, which in turn may connect to long-term archives and preservation systems HTTP , FTP , WebDAV , git Registry (metadata) the reproducibility service can deliver metadata on published ERC to registries/catalogues/search portals directly and mediately via data repositories; the service can also retrieve/harvest contextual metadata during ERC creation to reduce required user inputs; users discover ERC via registries (proprietary) HTTP APIs, persistent identifiers ( DOI ), OAI-PMH Software repository software repository provide software artifacts during ERC creation and store executable runtime environments HTTP APIs Archives and digital preservation systems saving ERCs in preservation systems includes extended data and metadata management (cf. private/group domain vs. persistent domain in the Curation Domain Model (in German)), because a different kind of access and re-use is of concern for these systems; these concerns are relevant in so far as the intermediary data repositories must be supported, but further aspects, e.g. long-term access rights, are only mediately relevant for the reproducibility service metadata in JSON and XML provided as part of HTTP requests or as files within payloads 3.2 Technical context \u00b6 All components use HTTP(S) over cable networks connections for communication (metadata documents, ERC, Linux containers, etc.).","title":"03 system scope and context"},{"location":"03_system-scope-and-context/#3-system-scope-and-context","text":"","title":"3. System scope and context"},{"location":"03_system-scope-and-context/#31-business-context","text":"Communication partner Exchanged data Technology/protocol Reproducibility service , e.g. o2r reference implementation publication platforms utilize creation and examination services for ERC; reproducibility service uses different supporting services to retrieve software artifacts, store runtime environment images, execute workflows, and save complete ERC HTTP APIs Publishing platform , e.g. online journal website or review system users access ERC status and metadata via search results and paper landing pages; review process integrates ERC details and supports manipulation; system's API using HTTP with JSON payload Collaboration platform provide means to collaboratively work on data, code, or text; such platforms support both public and private (shared) digital workspaces HTTP ID provider retrieve unique user IDs, user metadata, and authentication tokens; user must log in with the provider HTTP Execution infrastructure ERC can be executed using a shared/distributed infrastructure HTTP Data repository the reproducibility service fetches (a) content for ERC creation, or (b) complete ERC, from different sources; it stores created ERC persistently at suitable repositories, which in turn may connect to long-term archives and preservation systems HTTP , FTP , WebDAV , git Registry (metadata) the reproducibility service can deliver metadata on published ERC to registries/catalogues/search portals directly and mediately via data repositories; the service can also retrieve/harvest contextual metadata during ERC creation to reduce required user inputs; users discover ERC via registries (proprietary) HTTP APIs, persistent identifiers ( DOI ), OAI-PMH Software repository software repository provide software artifacts during ERC creation and store executable runtime environments HTTP APIs Archives and digital preservation systems saving ERCs in preservation systems includes extended data and metadata management (cf. private/group domain vs. persistent domain in the Curation Domain Model (in German)), because a different kind of access and re-use is of concern for these systems; these concerns are relevant in so far as the intermediary data repositories must be supported, but further aspects, e.g. long-term access rights, are only mediately relevant for the reproducibility service metadata in JSON and XML provided as part of HTTP requests or as files within payloads","title":"3.1 Business context"},{"location":"03_system-scope-and-context/#32-technical-context","text":"All components use HTTP(S) over cable networks connections for communication (metadata documents, ERC, Linux containers, etc.).","title":"3.2 Technical context"},{"location":"04_solution-strategy/","text":"4. Solution strategy \u00b6 This section provides a short overview of architecture decisions and for some the reasoning behind them. Web API \u00b6 The developed solution is set in an existing system of services, and first and foremost must integrate well with these systems, focussing on the specific missing features of building and running ERCs. These features are provided via a well-defined RESTful API . Microservices \u00b6 To allow a dynamic development and support the large variety of skills, all server-side features are developed in independent microservices . These microservices handle only specific functional parts of the API and allow independent development and deployment cycles. Core components are developed using server-side JavaScript based on Node.js with Express while other components are implemented in Python. We accept this diversification increases complexity of both development and testing environments and the deployment of said services. Required documentation is minimal. The typical structure should follow common practices of the respective language and tools. Storage and intra-service communication \u00b6 In accordance with the system scope, there is no reliable storage solution implemented. The microservices simply share a common pointer to a local file system path. Storage of ERC is only implemented to make the solution independent during development and for the needs of core functionality (temporal storage), but it is not a feature the solution will eventually provide. The unifying component of the architecture is the database . It is known to all microservices. Some microservices communicate via an eventing mechanism for real-time updates, such as the search database and the component providing live updates to the user via WebSockets. The eventing is based on the operation log of the database (which is normally used to synchronise database nodes). This is a clear misuse of an internal feature , but a lot simpler than maintaining a full-blown eventing solution. Demonstration, user data & authentication \u00b6 To be able to demonstrate the system, a browser-based client application is developed. It uses the RESTful API to control the system. OAuth 2.0 is used for authentication and minimal information, which is already public, is stored for each user. This information is shared between all services which require authentication via the database. The client application manages the control flow of all user interactions. Tools \u00b6 If standalone tools are developed, they provide a command-line interface (CLI). The CLI allows integration into microservices when needed and to package tools including their dependencies as containers and distributing them using a container registry. These 2nd level containers are started by the microservices and can run either next to the microservices or in an independent container cluster, providing scalability. It must only be ensured they are correctly configured in each microservice. The only required documentation is the installation into a container and usage of the CLI.","title":"04 solution strategy"},{"location":"04_solution-strategy/#4-solution-strategy","text":"This section provides a short overview of architecture decisions and for some the reasoning behind them.","title":"4. Solution strategy"},{"location":"04_solution-strategy/#web-api","text":"The developed solution is set in an existing system of services, and first and foremost must integrate well with these systems, focussing on the specific missing features of building and running ERCs. These features are provided via a well-defined RESTful API .","title":"Web API"},{"location":"04_solution-strategy/#microservices","text":"To allow a dynamic development and support the large variety of skills, all server-side features are developed in independent microservices . These microservices handle only specific functional parts of the API and allow independent development and deployment cycles. Core components are developed using server-side JavaScript based on Node.js with Express while other components are implemented in Python. We accept this diversification increases complexity of both development and testing environments and the deployment of said services. Required documentation is minimal. The typical structure should follow common practices of the respective language and tools.","title":"Microservices"},{"location":"04_solution-strategy/#storage-and-intra-service-communication","text":"In accordance with the system scope, there is no reliable storage solution implemented. The microservices simply share a common pointer to a local file system path. Storage of ERC is only implemented to make the solution independent during development and for the needs of core functionality (temporal storage), but it is not a feature the solution will eventually provide. The unifying component of the architecture is the database . It is known to all microservices. Some microservices communicate via an eventing mechanism for real-time updates, such as the search database and the component providing live updates to the user via WebSockets. The eventing is based on the operation log of the database (which is normally used to synchronise database nodes). This is a clear misuse of an internal feature , but a lot simpler than maintaining a full-blown eventing solution.","title":"Storage and intra-service communication"},{"location":"04_solution-strategy/#demonstration-user-data-authentication","text":"To be able to demonstrate the system, a browser-based client application is developed. It uses the RESTful API to control the system. OAuth 2.0 is used for authentication and minimal information, which is already public, is stored for each user. This information is shared between all services which require authentication via the database. The client application manages the control flow of all user interactions.","title":"Demonstration, user data &amp; authentication"},{"location":"04_solution-strategy/#tools","text":"If standalone tools are developed, they provide a command-line interface (CLI). The CLI allows integration into microservices when needed and to package tools including their dependencies as containers and distributing them using a container registry. These 2nd level containers are started by the microservices and can run either next to the microservices or in an independent container cluster, providing scalability. It must only be ensured they are correctly configured in each microservice. The only required documentation is the installation into a container and usage of the CLI.","title":"Tools"},{"location":"05_building-block-view/","text":"5. Building block view \u00b6 5.1 Refinement Level 1 \u00b6 5.1.1 Blackbox Publication Platforms \u00b6 Publications platforms are the online interaction points of users with scientific works. Users create publications, e.g. submitting to a scientific journal, publishing on a pre-print server, publishing on a self-hosted website, or collaborating in online repositories. Users examine publications, e.g. browsing, searching, reading, downloading, or reviewing. 5.1.2 Blackbox ID Provider \u00b6 Identification information of distributed systems is crucial, and for security reasons as well as for limiting manual reproduction of metadata, a central service can provide all of unique identification of users and metadata on users , authentication of users, and metadata on a user's works , e.g. publications or ERC. Persistent identifiers for artifacts in the reproducibility service itself are not required , as these are provided by data storage and registries. However, services such as ePIC could allow to retrieve persistent IDs. 5.1.3 Blackbox Execution Infrastructure \u00b6 The execution infrastructure provides CPU time and temporary result storage space for execution of ERC, both \"as is\" and with manipulation, i.e. changed parameters. It also provides different architectures and operating system kernel configurations which are outside of the scope of ERC's runtime environments based on containers. 5.1.4 Blackbox Data Repositories \u00b6 Data repositories are all services storing data but not software. More specifically, they may store software \"as data\", but not with software-specific features such as code versioning or installation binaries for different computer architectures. Data repositories may be self-hosted or public/free, domain-specific or generic. They typically provide persistent identifiers or handles, e.g. a DOI or URN . They are used both for loading created ERC and for storing the ERC created by the reproducibility service. 5.1.5 Blackbox Registries \u00b6 Registries are metadata indexes or catalogues. They are recipients of metadata exports by the reproducibility service to share information about ERC, e.g. add a new ERC to an author's profile. This requires the reproducibility services to translate the internal metadata model into the recipients data model and encoding. They are sources of metadata during ERC creation when the information in the fetched content is used to query registries for additional information which can be offered to the user. 5.1.6 Blackbox Software Repositories \u00b6 Software repositories are a source and a sink for software at different abstraction levels. They are a source for software dependencies, such as system packages for installing a library. They are a sink for executable images, which comprise a number of software artifacts and their dependencies, for a specific ERC instance. 5.2 Refinement Level 2 \u00b6 5.2.1 Whitebox Publication Platforms \u00b6 Publication platforms can be roughly divided into two groups. They can be either specific journals hosted independently, such as JStatSoft or JOSS , or a larger platform provided by a publisher to multiple journals, such as ScienceDirect , MDPI , SpringerLink , or PLOS . To some extend, pre-print servers, for example OSF or arXiv.org , can also fall into the latter category. Integration with the reproducibility service can happen via plug-ins to generic software, e.g. OJS , or by bespoke extensions. Integrations are based on the service's public API. 5.2.2 Whitebox ID Provider \u00b6 The reproducibility service uses ORCID to authenticate users and retrieve user metadata. The reproducibility service does not use the ORCID authorisation to edit ORCID user data or retrieve non-public data from ORCID, thus this process is pseudo-authentication using OAuth . Internally, the user's public ORCID is the main identifier. User have different levels, which allow different actions, such as \"registered user\" or \"administrator\". These levels are stored in the reproducibility service. 5.2.3 Whitebox Execution Infrastructure \u00b6 Such an infrastructure could be either self-hosted, e.g. Docker Swarm -based, use a cloud service provider, such as Amazon EC2 , Docker Cloud , or even use continuous integration services such as Travis CI or Gitlab CI . Or it could use a combination of these. Not all of these options provide the flexibility to provide configurations outside of containers, for example specific operating system kernels. An implementing system must manage these independently, for example by mapping ERC requirements like an operating system, to a part of the execution infrastructure that supports it. 5.2.4 Whitebox Data Repositories \u00b6 The reproducibility service does not persistently store anything . It only keeps copies of files during creation and inspection. So where are ERCs saved and where is their data coming from? Collaboration platforms , e.g. ownCloud/Sciebo , GitHub , ShareLatex , OSF , allow users to create, store, and share their research (code, text, data, et cetera). Besides being an interaction platform for users, they can also be seen simply as a data repository. The reproducibility service fetches contents for building an ERC from them based on public links, e.g. a public GitHub repository or shared Sciebo folder. It is possible to link ERC creation to an project/repository under development on a collaboration platform as to trigger an ERC (re-)creation or execution when changes are made. Protocols: WebDAV , ownCloud , HTTP (including webhooks ), git Domain data repositories , e.g. PANGAEA or GFZ Data Services , can be accessed by the reproducibility service during creation and execution of ERC to download data. Allowing access to data repositories reduces data duplication but requires control over/trust in the respective repository. Protocol: HTTP APIs Generic Repositories , e.g. Zenodo , Mendeley Data , Figshare , OSF , provide (a) access to complete ERC stored in repositories for inspection and execution by the reproducibility service, and (b) storage of created ERC. repositories. Protocols: (authenticated) HTTP APIs Archives and digital preservation solutions can provide long-term preservation of ERC. The data repository and/or one of the involved platform providers are responsible for preservation. A data repository might save the hosted content to an archive, be regularly harvested by an archive, or be part of a distributed dark archive, e.g. CLOCKSS . A platform provider might supply a digital preservation service, e.g. an installation of Archivematica . Protocol: HTTP carrying bitstreams and metadata Data Curation Continuum The Data Curation Continuum (cf. diagram by Andre Treloar ), describes how data moves from the private domain of a researcher to the public domain of data repositories over the course of conducting research. It describes the properties of data and important aspects of the transitions. In a publishing process based on the reproducibility service, the full migration process is run through. 5.2.5 Whitebox Registries \u00b6 Research data registries and websites, for example ( CRIS , DataCite , Google Scholar , Scopus , Altmetric , to name just a few, collect metadata on publications and provide services with this data. Services comprise discovery but also derivation of citation data and creating networks of researchers and publications. The listed examples include open platforms, commercial solutions, and institution-specific platforms. Some of the registries offer a public, well-defined API to retrieve structured metadata and to create new records. Protocol: HTTP APIs 5.2.6 Whitebox Software Repositories \u00b6 5.2.6.1 Blackbox Package repositories \u00b6 Package repositories are used during ERC creation to download and install software artifacts for specific operating systems, e.g. Debian APT or Ubuntu Launchpad , for specific programming languages or environments, e.g. CRAN , or from source, e.g. GitHub . 5.2.6.2 Blackbox Container registries \u00b6 Container registries such as Docker Hub , Quay , self-hosted Docker Registry 2.0 or Amazon ERC , store executable images of runtime environments. They can be used to distribute the runtime environments across the execution infrastructure and provide an intermediate ephemeral storage for the reproducibility service. 5.2.7 Whitebox Reproducibility Service \u00b6 5.2.7.1 Blackbox Webserver \u00b6 A webserver handles all incoming calls to the API ( /api/v1/ ) via HTTPS ( HTTP is redirected) and distributes them to the respective microservice. A working nginx configuration is available in the test setup . 5.2.7.2 Blackbox UI \u00b6 The UI is a web application based on Angular JS , see o2r-platform . It connects to all microservices via their API and is served using the same webserver as the API. 5.2.7.3 Blackbox Microservices \u00b6 The reproducibility service uses a microservice architecture to separate functionality defined by the web API specification into manageable units. This allows scalability (selected microservices can be deployed as much as needed) and technology independence for each use case and developer. The microservices all access one main database and a shared file storage. 5.2.7.4 Blackbox Tools \u00b6 Some functionality is developed as standalone tools and used as such in the microservices instead of re-implementing features. These tools are integrated via their command line interface (CLI) and executed as 2nd level containers by microservices. 5.2.7.5 Blackbox Databases \u00b6 The main document database is the unifying element of the microservice architecture. All information shared between microservices or transactions between microservices are made via the database, including session state handling for authentication. A search database is used for full-text search and advanced queries. The database's operation log, normally used for synchronization between database nodes, is also used for event-driven communication between microservices, and synchronization between main document database and search index. Note This eventing \"hack\" is expected to be replaced by a proper eventing layer for productive deployments. 5.2.7.6 Blackbox Ephemeral file storage \u00b6 After loading from external sources and during creation of ERC, the files are stored in a file storage shared between the microservices. The file structure is known to each microservice and read/write operations happen as needed. 5.3 Refinement Level 3 \u00b6 5.3.1 Whitebox microservices \u00b6 Each microservice is encapsulated as a Docker container running at its own port on an internal network and only serving its respective API path. Internal communication between the webserver and the microservices is unencrypted, i.e. HTTP . Testing : the reference implementation provides instructions on running a local instance ofr the microservices and the demonstration UI. Development : the o2r-platform GitHub project contains docker-compose configurations to run all microservices, see repository file docker-compose.yml and the project's README.md for instructions. The following table describes the microservices, their endpoints, and their features. Project API path Language Description muncher /api/v1/compendium and /api/v1/job JavaScript (Node.js) core component for CRUD of compendia and jobs (ERC execution) loader /api/v1/compendium ( HTTP POST only) JavaScript (Node.js) load workspaces from repositories and collaboration platforms finder /api/v1/search JavaScript (Node.js) discovery and search, synchronizes the database with a search database (Elasticsearch) and exposes read-only search endpoints transporter ~ /data/ and ~* \\.(zip|tar|tar.gz) JavaScript (Node.js) downloads of compendia in zip or (gzipped) tar formats informer ~* \\.io JavaScript (Node.js) socket.io -based WebSockets for live updates to the UI based on database event log, e.g. job progress inspecter /api/v1/inspection R ( plumber ) allow inspection of non-text-based file formats, e.g. .Rdata substituter /api/v1/substitution JavaScript (Node.js) create new ERCs based on existing ones by substituting files manipulater under development -- provide back-end containers for interactive ERCs ERC exporting \u00b6 Project API path Language Description shipper /api/v1/shipment Python ship ERCs, including packaging, and their metadata to third party repositories and archives Authentication \u00b6 Project API path Language Description bouncer /api/v1/auth , /api/v1/user/ JavaScript (Node.js) authentication service and user management (whoami, level changing) Supporting services \u00b6 Existing software projects can be re-used for common functionality, such as gathering statistics. These supporting services run alongside the microservices in their own containers accessible via the main webservice. Project Description Piwik collect user statistics 5.3.2 Whitebox database \u00b6 Two databases are used. MongoDB document database with enabled replica-set oplog for eventing. Collections: users sessions compendia jobs shipments The MongoDB API is used by connecting microservices via suitable client packages, which are available for all required languages. Elasticsearch search index , kept in sync with the main document database by the microservice finder . The ids are mapped to support update and delete operations. The two main resources of the API are kept in separate indices due to their different structure/mappings : compendia with type compendia jobs with type jobs The search index is accessed by clients through the search endpoint provided by finder . 5.3.3 Whitebox tools \u00b6 project language description meta Python scripts for extraction, translation and validation of metadata; for details see metadata documentation containerit R generation of Dockerfiles based on R sessions and scripts Each tool's code repository includes one or more Dockerfiles , which are automatically build and published on Docker Hub. The microservices use the tool's Docker images to execute the tools instead of installing all their dependencies into the microservices. The advantages are a controlled environment for the tool usage, independent development cycles and updating of the tools, smaller independent images for the microservices, and scalability. Meta \u00b6 Meta provides a CLI for each step of the metadata processing required in the reproducibility service as shown by the following diagram. After each step the created metadata is saved as a file per model to a directory in the compendium. A detailed view of the meta tool usage in the creation process is provided in the runtime view ERC Creation . Containerit \u00b6 The containerit tool extracts required dependencies from ERC main documents and uses the information and external configuration to create a Dockerfile, which executes the full computational workflow when the container is started. Its main strategy is to analyse the session at the end of executing the full workflow. 5.3.4 Whitebox ephemeral file storage \u00b6 A host directory is mounted into every container to the location /tmp/o2r .","title":"05 building block view"},{"location":"05_building-block-view/#5-building-block-view","text":"","title":"5. Building block view"},{"location":"05_building-block-view/#51-refinement-level-1","text":"","title":"5.1 Refinement Level 1"},{"location":"05_building-block-view/#511-blackbox-publication-platforms","text":"Publications platforms are the online interaction points of users with scientific works. Users create publications, e.g. submitting to a scientific journal, publishing on a pre-print server, publishing on a self-hosted website, or collaborating in online repositories. Users examine publications, e.g. browsing, searching, reading, downloading, or reviewing.","title":"5.1.1 Blackbox Publication Platforms"},{"location":"05_building-block-view/#512-blackbox-id-provider","text":"Identification information of distributed systems is crucial, and for security reasons as well as for limiting manual reproduction of metadata, a central service can provide all of unique identification of users and metadata on users , authentication of users, and metadata on a user's works , e.g. publications or ERC. Persistent identifiers for artifacts in the reproducibility service itself are not required , as these are provided by data storage and registries. However, services such as ePIC could allow to retrieve persistent IDs.","title":"5.1.2 Blackbox ID Provider"},{"location":"05_building-block-view/#513-blackbox-execution-infrastructure","text":"The execution infrastructure provides CPU time and temporary result storage space for execution of ERC, both \"as is\" and with manipulation, i.e. changed parameters. It also provides different architectures and operating system kernel configurations which are outside of the scope of ERC's runtime environments based on containers.","title":"5.1.3 Blackbox Execution Infrastructure"},{"location":"05_building-block-view/#514-blackbox-data-repositories","text":"Data repositories are all services storing data but not software. More specifically, they may store software \"as data\", but not with software-specific features such as code versioning or installation binaries for different computer architectures. Data repositories may be self-hosted or public/free, domain-specific or generic. They typically provide persistent identifiers or handles, e.g. a DOI or URN . They are used both for loading created ERC and for storing the ERC created by the reproducibility service.","title":"5.1.4 Blackbox Data Repositories"},{"location":"05_building-block-view/#515-blackbox-registries","text":"Registries are metadata indexes or catalogues. They are recipients of metadata exports by the reproducibility service to share information about ERC, e.g. add a new ERC to an author's profile. This requires the reproducibility services to translate the internal metadata model into the recipients data model and encoding. They are sources of metadata during ERC creation when the information in the fetched content is used to query registries for additional information which can be offered to the user.","title":"5.1.5 Blackbox Registries"},{"location":"05_building-block-view/#516-blackbox-software-repositories","text":"Software repositories are a source and a sink for software at different abstraction levels. They are a source for software dependencies, such as system packages for installing a library. They are a sink for executable images, which comprise a number of software artifacts and their dependencies, for a specific ERC instance.","title":"5.1.6 Blackbox Software Repositories"},{"location":"05_building-block-view/#52-refinement-level-2","text":"","title":"5.2 Refinement Level 2"},{"location":"05_building-block-view/#521-whitebox-publication-platforms","text":"Publication platforms can be roughly divided into two groups. They can be either specific journals hosted independently, such as JStatSoft or JOSS , or a larger platform provided by a publisher to multiple journals, such as ScienceDirect , MDPI , SpringerLink , or PLOS . To some extend, pre-print servers, for example OSF or arXiv.org , can also fall into the latter category. Integration with the reproducibility service can happen via plug-ins to generic software, e.g. OJS , or by bespoke extensions. Integrations are based on the service's public API.","title":"5.2.1 Whitebox Publication Platforms"},{"location":"05_building-block-view/#522-whitebox-id-provider","text":"The reproducibility service uses ORCID to authenticate users and retrieve user metadata. The reproducibility service does not use the ORCID authorisation to edit ORCID user data or retrieve non-public data from ORCID, thus this process is pseudo-authentication using OAuth . Internally, the user's public ORCID is the main identifier. User have different levels, which allow different actions, such as \"registered user\" or \"administrator\". These levels are stored in the reproducibility service.","title":"5.2.2 Whitebox ID Provider"},{"location":"05_building-block-view/#523-whitebox-execution-infrastructure","text":"Such an infrastructure could be either self-hosted, e.g. Docker Swarm -based, use a cloud service provider, such as Amazon EC2 , Docker Cloud , or even use continuous integration services such as Travis CI or Gitlab CI . Or it could use a combination of these. Not all of these options provide the flexibility to provide configurations outside of containers, for example specific operating system kernels. An implementing system must manage these independently, for example by mapping ERC requirements like an operating system, to a part of the execution infrastructure that supports it.","title":"5.2.3 Whitebox Execution Infrastructure"},{"location":"05_building-block-view/#524-whitebox-data-repositories","text":"The reproducibility service does not persistently store anything . It only keeps copies of files during creation and inspection. So where are ERCs saved and where is their data coming from? Collaboration platforms , e.g. ownCloud/Sciebo , GitHub , ShareLatex , OSF , allow users to create, store, and share their research (code, text, data, et cetera). Besides being an interaction platform for users, they can also be seen simply as a data repository. The reproducibility service fetches contents for building an ERC from them based on public links, e.g. a public GitHub repository or shared Sciebo folder. It is possible to link ERC creation to an project/repository under development on a collaboration platform as to trigger an ERC (re-)creation or execution when changes are made. Protocols: WebDAV , ownCloud , HTTP (including webhooks ), git Domain data repositories , e.g. PANGAEA or GFZ Data Services , can be accessed by the reproducibility service during creation and execution of ERC to download data. Allowing access to data repositories reduces data duplication but requires control over/trust in the respective repository. Protocol: HTTP APIs Generic Repositories , e.g. Zenodo , Mendeley Data , Figshare , OSF , provide (a) access to complete ERC stored in repositories for inspection and execution by the reproducibility service, and (b) storage of created ERC. repositories. Protocols: (authenticated) HTTP APIs Archives and digital preservation solutions can provide long-term preservation of ERC. The data repository and/or one of the involved platform providers are responsible for preservation. A data repository might save the hosted content to an archive, be regularly harvested by an archive, or be part of a distributed dark archive, e.g. CLOCKSS . A platform provider might supply a digital preservation service, e.g. an installation of Archivematica . Protocol: HTTP carrying bitstreams and metadata Data Curation Continuum The Data Curation Continuum (cf. diagram by Andre Treloar ), describes how data moves from the private domain of a researcher to the public domain of data repositories over the course of conducting research. It describes the properties of data and important aspects of the transitions. In a publishing process based on the reproducibility service, the full migration process is run through.","title":"5.2.4 Whitebox Data Repositories"},{"location":"05_building-block-view/#525-whitebox-registries","text":"Research data registries and websites, for example ( CRIS , DataCite , Google Scholar , Scopus , Altmetric , to name just a few, collect metadata on publications and provide services with this data. Services comprise discovery but also derivation of citation data and creating networks of researchers and publications. The listed examples include open platforms, commercial solutions, and institution-specific platforms. Some of the registries offer a public, well-defined API to retrieve structured metadata and to create new records. Protocol: HTTP APIs","title":"5.2.5 Whitebox Registries"},{"location":"05_building-block-view/#526-whitebox-software-repositories","text":"","title":"5.2.6 Whitebox Software Repositories"},{"location":"05_building-block-view/#5261-blackbox-package-repositories","text":"Package repositories are used during ERC creation to download and install software artifacts for specific operating systems, e.g. Debian APT or Ubuntu Launchpad , for specific programming languages or environments, e.g. CRAN , or from source, e.g. GitHub .","title":"5.2.6.1 Blackbox Package repositories"},{"location":"05_building-block-view/#5262-blackbox-container-registries","text":"Container registries such as Docker Hub , Quay , self-hosted Docker Registry 2.0 or Amazon ERC , store executable images of runtime environments. They can be used to distribute the runtime environments across the execution infrastructure and provide an intermediate ephemeral storage for the reproducibility service.","title":"5.2.6.2 Blackbox Container registries"},{"location":"05_building-block-view/#527-whitebox-reproducibility-service","text":"","title":"5.2.7 Whitebox Reproducibility Service"},{"location":"05_building-block-view/#5271-blackbox-webserver","text":"A webserver handles all incoming calls to the API ( /api/v1/ ) via HTTPS ( HTTP is redirected) and distributes them to the respective microservice. A working nginx configuration is available in the test setup .","title":"5.2.7.1 Blackbox Webserver"},{"location":"05_building-block-view/#5272-blackbox-ui","text":"The UI is a web application based on Angular JS , see o2r-platform . It connects to all microservices via their API and is served using the same webserver as the API.","title":"5.2.7.2 Blackbox UI"},{"location":"05_building-block-view/#5273-blackbox-microservices","text":"The reproducibility service uses a microservice architecture to separate functionality defined by the web API specification into manageable units. This allows scalability (selected microservices can be deployed as much as needed) and technology independence for each use case and developer. The microservices all access one main database and a shared file storage.","title":"5.2.7.3 Blackbox Microservices"},{"location":"05_building-block-view/#5274-blackbox-tools","text":"Some functionality is developed as standalone tools and used as such in the microservices instead of re-implementing features. These tools are integrated via their command line interface (CLI) and executed as 2nd level containers by microservices.","title":"5.2.7.4 Blackbox Tools"},{"location":"05_building-block-view/#5275-blackbox-databases","text":"The main document database is the unifying element of the microservice architecture. All information shared between microservices or transactions between microservices are made via the database, including session state handling for authentication. A search database is used for full-text search and advanced queries. The database's operation log, normally used for synchronization between database nodes, is also used for event-driven communication between microservices, and synchronization between main document database and search index. Note This eventing \"hack\" is expected to be replaced by a proper eventing layer for productive deployments.","title":"5.2.7.5 Blackbox Databases"},{"location":"05_building-block-view/#5276-blackbox-ephemeral-file-storage","text":"After loading from external sources and during creation of ERC, the files are stored in a file storage shared between the microservices. The file structure is known to each microservice and read/write operations happen as needed.","title":"5.2.7.6 Blackbox Ephemeral file storage"},{"location":"05_building-block-view/#53-refinement-level-3","text":"","title":"5.3 Refinement Level 3"},{"location":"05_building-block-view/#531-whitebox-microservices","text":"Each microservice is encapsulated as a Docker container running at its own port on an internal network and only serving its respective API path. Internal communication between the webserver and the microservices is unencrypted, i.e. HTTP . Testing : the reference implementation provides instructions on running a local instance ofr the microservices and the demonstration UI. Development : the o2r-platform GitHub project contains docker-compose configurations to run all microservices, see repository file docker-compose.yml and the project's README.md for instructions. The following table describes the microservices, their endpoints, and their features. Project API path Language Description muncher /api/v1/compendium and /api/v1/job JavaScript (Node.js) core component for CRUD of compendia and jobs (ERC execution) loader /api/v1/compendium ( HTTP POST only) JavaScript (Node.js) load workspaces from repositories and collaboration platforms finder /api/v1/search JavaScript (Node.js) discovery and search, synchronizes the database with a search database (Elasticsearch) and exposes read-only search endpoints transporter ~ /data/ and ~* \\.(zip|tar|tar.gz) JavaScript (Node.js) downloads of compendia in zip or (gzipped) tar formats informer ~* \\.io JavaScript (Node.js) socket.io -based WebSockets for live updates to the UI based on database event log, e.g. job progress inspecter /api/v1/inspection R ( plumber ) allow inspection of non-text-based file formats, e.g. .Rdata substituter /api/v1/substitution JavaScript (Node.js) create new ERCs based on existing ones by substituting files manipulater under development -- provide back-end containers for interactive ERCs","title":"5.3.1 Whitebox microservices"},{"location":"05_building-block-view/#erc-exporting","text":"Project API path Language Description shipper /api/v1/shipment Python ship ERCs, including packaging, and their metadata to third party repositories and archives","title":"ERC exporting"},{"location":"05_building-block-view/#authentication","text":"Project API path Language Description bouncer /api/v1/auth , /api/v1/user/ JavaScript (Node.js) authentication service and user management (whoami, level changing)","title":"Authentication"},{"location":"05_building-block-view/#supporting-services","text":"Existing software projects can be re-used for common functionality, such as gathering statistics. These supporting services run alongside the microservices in their own containers accessible via the main webservice. Project Description Piwik collect user statistics","title":"Supporting services"},{"location":"05_building-block-view/#532-whitebox-database","text":"Two databases are used. MongoDB document database with enabled replica-set oplog for eventing. Collections: users sessions compendia jobs shipments The MongoDB API is used by connecting microservices via suitable client packages, which are available for all required languages. Elasticsearch search index , kept in sync with the main document database by the microservice finder . The ids are mapped to support update and delete operations. The two main resources of the API are kept in separate indices due to their different structure/mappings : compendia with type compendia jobs with type jobs The search index is accessed by clients through the search endpoint provided by finder .","title":"5.3.2 Whitebox database"},{"location":"05_building-block-view/#533-whitebox-tools","text":"project language description meta Python scripts for extraction, translation and validation of metadata; for details see metadata documentation containerit R generation of Dockerfiles based on R sessions and scripts Each tool's code repository includes one or more Dockerfiles , which are automatically build and published on Docker Hub. The microservices use the tool's Docker images to execute the tools instead of installing all their dependencies into the microservices. The advantages are a controlled environment for the tool usage, independent development cycles and updating of the tools, smaller independent images for the microservices, and scalability.","title":"5.3.3 Whitebox tools"},{"location":"05_building-block-view/#meta","text":"Meta provides a CLI for each step of the metadata processing required in the reproducibility service as shown by the following diagram. After each step the created metadata is saved as a file per model to a directory in the compendium. A detailed view of the meta tool usage in the creation process is provided in the runtime view ERC Creation .","title":"Meta"},{"location":"05_building-block-view/#containerit","text":"The containerit tool extracts required dependencies from ERC main documents and uses the information and external configuration to create a Dockerfile, which executes the full computational workflow when the container is started. Its main strategy is to analyse the session at the end of executing the full workflow.","title":"Containerit"},{"location":"05_building-block-view/#534-whitebox-ephemeral-file-storage","text":"A host directory is mounted into every container to the location /tmp/o2r .","title":"5.3.4 Whitebox ephemeral file storage"},{"location":"06_runtime-view/","text":"6. Runtime view \u00b6 The runtime view describes the interaction between the static building blocks. It cannot cover all potential cases and focusses on the following main scenarios. Scenario Purpose and overview ERC Creation The most important workflow for an author is creating an ERC from his workspace of data, code and documentation. The author can provide these resources as a direct upload, but a more comfortable process is loading the files from a collaboration platform. Three microservices are core to this scenario: loader , muncher , and shipper . ERC Inspection The most important workflow for a reviewer or reader is executing the analysis encapsulated in an ERC. The execution comprises creation of configuration files (if missing) from metadata, compiling the a display file using the actual analysis, and saving the used runtime environment. The core microservice for this scenario is muncher . 6.1 ERC Creation \u00b6 First, the user initiates a creation of a new ERC based on a workspace containing at least a viewable file (e.g. an HTML document or a plot) based on the code and instructions provided in a either a script or literate programming document ), and any other data. The loader runs a series of steps: fetching the files, checking the incoming workspace structure, extracting raw metadata from the workspace, brokering raw metadata to o2r metadata, and saving the compendium to the database. The compendium is now a non-public candidate , meaning only the uploading user or admin users can see and edit it. All metadata processing is based on the tool meta . Then the user opens the candidate compendium, reviews and completes the metadata, and saves it. Saving triggers a metadata validation in muncher . If the validation succeeds, the metadata is brokered to several output formats as files within the compendium using meta , and then re-loaded to the database for better searchability . Next, the user must start a job to add the ERC configuration and runtime environment to the workspace, which are core elements of an ERC. The ERC configuration is a file generated from the user-provided metadata (see ERC specification ). The runtime environment consists of two parts: (a) the runtime manifest, which is created by executing the workflow once in a container based on the tool containerit ; and (b) the runtime image, which is built from the runtime manifest. A user may provide the ERC configuration file and the runtime manifest with the workspace for fine-grained control; the generation steps are skipped then. Finally the user starts a shipment of the compendium to a data repository. The shipper manages this two step process. The separate \"create\" and \"publish\" steps allow checking the shipped files and avoid unintentional shipments, because a published shipment creates an non-erasable public resource. In the code The loader has two core controllers for direct upload and load from a collaboration platform. Their core chain of functions are realised as JavaScript Promises , see the code for loader and uploader respectively. The respective steps are shared between these two cases where possible, i.e. starting with the step stripSingleBasedir . 6.2 ERC Inspection \u00b6 The user initiates an inspection of an existing ERC by providing a reference such as DOI or URL. loader retrieves the compendium files, saves them locally and loads the contained metadata. Then the user can start a new job for the compendium. muncher checks the request, creates a new job in the database and returns the job ID. The user's client can use the ID to connect to the live logs provided by informer . All following steps by muncher regularly update the database, whose change events informer uses to continuously update client via WebSockets. The job starts with creating a copy of the compendium's files for the job. A copy-on-write filesystem is advantageous for this step. Then the archived runtime image is loaded from the file in the compendium into a runtime repository. This repository may be remote (either public or private, e.g. based on Docker Registry , ECR or GitLab ) or simply the local image storage. Then all files except the runtime image archive are packed so they can be send to a container runtime. The container runtime can be local (e.g. the Docker daemon), or a container orchestration such as Kubernetes . It provides log updates as a stream to muncher , which updates the database, whose changes trigger updates of the user interface via informer . When the container is finished, muncher compares the created outputs with the ones provided in the compendium and provides the result to the user. In the code The muncher has two core resources: a compendium represents an ERC, a job represents a \"run\" of an ERC, i.e. the building, running, and saving of the runtime environment including execution of the contained workflow. The core function for this is the Executor , which chains a number of steps using JavaScript Promises , see the code . The check uses the tool erc-checker .","title":"06 runtime view"},{"location":"06_runtime-view/#6-runtime-view","text":"The runtime view describes the interaction between the static building blocks. It cannot cover all potential cases and focusses on the following main scenarios. Scenario Purpose and overview ERC Creation The most important workflow for an author is creating an ERC from his workspace of data, code and documentation. The author can provide these resources as a direct upload, but a more comfortable process is loading the files from a collaboration platform. Three microservices are core to this scenario: loader , muncher , and shipper . ERC Inspection The most important workflow for a reviewer or reader is executing the analysis encapsulated in an ERC. The execution comprises creation of configuration files (if missing) from metadata, compiling the a display file using the actual analysis, and saving the used runtime environment. The core microservice for this scenario is muncher .","title":"6. Runtime view"},{"location":"06_runtime-view/#61-erc-creation","text":"First, the user initiates a creation of a new ERC based on a workspace containing at least a viewable file (e.g. an HTML document or a plot) based on the code and instructions provided in a either a script or literate programming document ), and any other data. The loader runs a series of steps: fetching the files, checking the incoming workspace structure, extracting raw metadata from the workspace, brokering raw metadata to o2r metadata, and saving the compendium to the database. The compendium is now a non-public candidate , meaning only the uploading user or admin users can see and edit it. All metadata processing is based on the tool meta . Then the user opens the candidate compendium, reviews and completes the metadata, and saves it. Saving triggers a metadata validation in muncher . If the validation succeeds, the metadata is brokered to several output formats as files within the compendium using meta , and then re-loaded to the database for better searchability . Next, the user must start a job to add the ERC configuration and runtime environment to the workspace, which are core elements of an ERC. The ERC configuration is a file generated from the user-provided metadata (see ERC specification ). The runtime environment consists of two parts: (a) the runtime manifest, which is created by executing the workflow once in a container based on the tool containerit ; and (b) the runtime image, which is built from the runtime manifest. A user may provide the ERC configuration file and the runtime manifest with the workspace for fine-grained control; the generation steps are skipped then. Finally the user starts a shipment of the compendium to a data repository. The shipper manages this two step process. The separate \"create\" and \"publish\" steps allow checking the shipped files and avoid unintentional shipments, because a published shipment creates an non-erasable public resource. In the code The loader has two core controllers for direct upload and load from a collaboration platform. Their core chain of functions are realised as JavaScript Promises , see the code for loader and uploader respectively. The respective steps are shared between these two cases where possible, i.e. starting with the step stripSingleBasedir .","title":"6.1 ERC Creation"},{"location":"06_runtime-view/#62-erc-inspection","text":"The user initiates an inspection of an existing ERC by providing a reference such as DOI or URL. loader retrieves the compendium files, saves them locally and loads the contained metadata. Then the user can start a new job for the compendium. muncher checks the request, creates a new job in the database and returns the job ID. The user's client can use the ID to connect to the live logs provided by informer . All following steps by muncher regularly update the database, whose change events informer uses to continuously update client via WebSockets. The job starts with creating a copy of the compendium's files for the job. A copy-on-write filesystem is advantageous for this step. Then the archived runtime image is loaded from the file in the compendium into a runtime repository. This repository may be remote (either public or private, e.g. based on Docker Registry , ECR or GitLab ) or simply the local image storage. Then all files except the runtime image archive are packed so they can be send to a container runtime. The container runtime can be local (e.g. the Docker daemon), or a container orchestration such as Kubernetes . It provides log updates as a stream to muncher , which updates the database, whose changes trigger updates of the user interface via informer . When the container is finished, muncher compares the created outputs with the ones provided in the compendium and provides the result to the user. In the code The muncher has two core resources: a compendium represents an ERC, a job represents a \"run\" of an ERC, i.e. the building, running, and saving of the runtime environment including execution of the contained workflow. The core function for this is the Executor , which chains a number of steps using JavaScript Promises , see the code . The check uses the tool erc-checker .","title":"6.2 ERC Inspection"},{"location":"07_deployment-view/","text":"7. Deployment View \u00b6 7.1 Test server https://o2r.uni-muenster.de \u00b6 Motivation The o2r infrastructure is driven by the research community's need for user friendly and transparent but also scalable and reliable solutions to increase computational reproducibility in the scientific publication process. To retrieve feedback from the community (public demo) and to increase software quality (controlled non-development environment), the current development state is regularly published on a test server. Quality and/or Performance Features The server is managed completely with Ansible to ensure a well-document setup. The base operating system is CentOS Linux 7. The machine has 4 cores, 8 GB RAM, and a local storage ~100 GB, and runs on a VM host. The one machine in this deployment runs the full o2r reproducibility service, i.e. all microservices and a webserver to serve the user interfaces. It also runs the databases and ancillary services, such as a web traffic statistics service. When executing a compendium, the compendium workspace is packaged in a tarball and send to the Docker daemon. This allows easy switching to remote machines, but also has a performance disadvantage. Mapping of Building Blocks to Infrastructure All building blocks run in their own Docker container using an image provided via and build on Docker Hub using a Dockerfile included in each microservice's code repository . The server is managed by the o2r team; external building blocks are managed by the respective organisation/provider. 7.2 Production (sketch) \u00b6 Note This deployment view is a sketch for a potential productive deployment and intends to point out features of the chosen architecture and expected challenges or solutions. It is not implemented at the moment! Motivation A productive system must be reliable and scalable providing a single reproducibility service API endpoint. It must also adopt the distribution and deployments of the reproducibility service's microservices. Being based on containers it naturally uses one of the powerful orchestration engines, such as Docker Swarm or Kubernetes . It can also include multiple execution infrastructures to support multiple container software versions, different architectures, kernels, GPUs, or even specialised hardware. Operators of a reproducibility service can separate themselves from other operators by offering specific hardware or versions. Quality and/or Performance Features The services are redundantly provided via separated clusters of nodes for (a) running the reproducibility service's microservices and ancillary services, (b) running the document and search databases, (c) running ERC executions. Separating the clusters allows common security protocols, e.g. the tool and execution cluster should not be able to contact arbitrary websites. The software in the data cluster can run in containers or bare metal. The clusters for app and compendia have access to a common shared file storage, a potential bottleneck. Performance of microservices can be easily scaled by adding nodes to the respective clusters. The diversity of supported ERCs can be increased by providing different architectures and kernels, and hardware. Some requirements could be met on demand using virtualisation, such as a specific operating system version. Mapping of Building Blocks to Infrastructure The o2r reproducibility service and execution infrastructures are managed by the o2r team similar to the test server. The other big building blocks, like publishing platforms or data repositories, are managed by the respective organisations.","title":"07 deployment view"},{"location":"07_deployment-view/#7-deployment-view","text":"","title":"7. Deployment View"},{"location":"07_deployment-view/#71-test-server-httpso2runi-muensterde","text":"Motivation The o2r infrastructure is driven by the research community's need for user friendly and transparent but also scalable and reliable solutions to increase computational reproducibility in the scientific publication process. To retrieve feedback from the community (public demo) and to increase software quality (controlled non-development environment), the current development state is regularly published on a test server. Quality and/or Performance Features The server is managed completely with Ansible to ensure a well-document setup. The base operating system is CentOS Linux 7. The machine has 4 cores, 8 GB RAM, and a local storage ~100 GB, and runs on a VM host. The one machine in this deployment runs the full o2r reproducibility service, i.e. all microservices and a webserver to serve the user interfaces. It also runs the databases and ancillary services, such as a web traffic statistics service. When executing a compendium, the compendium workspace is packaged in a tarball and send to the Docker daemon. This allows easy switching to remote machines, but also has a performance disadvantage. Mapping of Building Blocks to Infrastructure All building blocks run in their own Docker container using an image provided via and build on Docker Hub using a Dockerfile included in each microservice's code repository . The server is managed by the o2r team; external building blocks are managed by the respective organisation/provider.","title":"7.1 Test server https://o2r.uni-muenster.de"},{"location":"07_deployment-view/#72-production-sketch","text":"Note This deployment view is a sketch for a potential productive deployment and intends to point out features of the chosen architecture and expected challenges or solutions. It is not implemented at the moment! Motivation A productive system must be reliable and scalable providing a single reproducibility service API endpoint. It must also adopt the distribution and deployments of the reproducibility service's microservices. Being based on containers it naturally uses one of the powerful orchestration engines, such as Docker Swarm or Kubernetes . It can also include multiple execution infrastructures to support multiple container software versions, different architectures, kernels, GPUs, or even specialised hardware. Operators of a reproducibility service can separate themselves from other operators by offering specific hardware or versions. Quality and/or Performance Features The services are redundantly provided via separated clusters of nodes for (a) running the reproducibility service's microservices and ancillary services, (b) running the document and search databases, (c) running ERC executions. Separating the clusters allows common security protocols, e.g. the tool and execution cluster should not be able to contact arbitrary websites. The software in the data cluster can run in containers or bare metal. The clusters for app and compendia have access to a common shared file storage, a potential bottleneck. Performance of microservices can be easily scaled by adding nodes to the respective clusters. The diversity of supported ERCs can be increased by providing different architectures and kernels, and hardware. Some requirements could be met on demand using virtualisation, such as a specific operating system version. Mapping of Building Blocks to Infrastructure The o2r reproducibility service and execution infrastructures are managed by the o2r team similar to the test server. The other big building blocks, like publishing platforms or data repositories, are managed by the respective organisations.","title":"7.2 Production (sketch)"},{"location":"arc42/","text":"About arc42 \u00b6 arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke.","title":"Arc42"},{"location":"arc42/#about-arc42","text":"arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke.","title":"About arc42"},{"location":"credits/","text":"Credits \u00b6 This specification and guides are developed by the members of the project Opening Reproducible Research ( Offene Reproduzierbare Forschung ) funded by the German Research Foundation (Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 274927273 ) under grant numbers PE 1632/10-1, KR 3930/3-1, and TR 864/6-1). Opening Reproducible Research (o2r, https://o2r.info/about ) is a DFG-funded research project by Institute for Geoinformatics ( ifgi ) and University and Regional Library ( ULB ), University of M\u00fcnster, Germany. Building on recent advances in mainstream IT, o2r envisions a new architecture for storing, executing and interacting with the original analysis environment alongside the corresponding research data and manuscript. This architecture evolves around so called Executable Research Compendia (ERC) as the container for both research, review, and archival. To cite this specification please use N\u00fcst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi: 10.5281/zenodo.2203844 For a complete list of publications, posters, presentations, and software projects from th2 o2r project please visit https://o2r.info/results/ . License \u00b6 The o2r architecture specification is licensed under Creative Commons CC0 1.0 Universal License , see file LICENSE . To the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work. This work is published from: Germany. About arc42 \u00b6 arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke. Build @@VERSION@@ @ @@TIMESTAMP@@","title":"Credits"},{"location":"credits/#credits","text":"This specification and guides are developed by the members of the project Opening Reproducible Research ( Offene Reproduzierbare Forschung ) funded by the German Research Foundation (Deutsche Forschungsgemeinschaft (DFG) - Projektnummer 274927273 ) under grant numbers PE 1632/10-1, KR 3930/3-1, and TR 864/6-1). Opening Reproducible Research (o2r, https://o2r.info/about ) is a DFG-funded research project by Institute for Geoinformatics ( ifgi ) and University and Regional Library ( ULB ), University of M\u00fcnster, Germany. Building on recent advances in mainstream IT, o2r envisions a new architecture for storing, executing and interacting with the original analysis environment alongside the corresponding research data and manuscript. This architecture evolves around so called Executable Research Compendia (ERC) as the container for both research, review, and archival. To cite this specification please use N\u00fcst, Daniel, 2018. Reproducibility Service for Executable Research Compendia: Technical Specifications and Reference Implementation. Zenodo. doi: 10.5281/zenodo.2203844 For a complete list of publications, posters, presentations, and software projects from th2 o2r project please visit https://o2r.info/results/ .","title":"Credits"},{"location":"credits/#license","text":"The o2r architecture specification is licensed under Creative Commons CC0 1.0 Universal License , see file LICENSE . To the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work. This work is published from: Germany.","title":"License"},{"location":"credits/#about-arc42","text":"arc42, the Template for documentation of software and system architecture. By Dr. Gernot Starke, Dr. Peter Hruschka and contributors. Template Revision: 7.0 EN (based on asciidoc), January 2017 \u00a9 We acknowledge that this document uses material from the arc 42 architecture template, http://www.arc42.de . Created by Dr. Peter Hruschka & Dr. Gernot Starke. Build @@VERSION@@ @ @@TIMESTAMP@@","title":"About arc42"},{"location":"glossary/","text":"Glossary \u00b6 Architecture \u00b6 See computer architecture . Computer Architecture \u00b6 [C]omputer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation. via Wikipedia Common architectures are amd64 or x86_64 . You can find out the operating system + architecture combinations supported by a specific Docker image, e.g. golang , with $ docker run mplatform/mquery golang Image: golang * Manifest List: Yes * Supported platforms: - linux/amd64 - linux/arm/v7 - linux/arm64/v8 - linux/386 - linux/ppc64le - linux/s390x - windows/amd64:10.0.14393.2068 - windows/amd64:10.0.16299.248 CRUD \u00b6 Basic operations on a digital artefact are create, read, update, and delete, often abbreviated to \" CRUD \". Digital Object Identifier \u00b6 See DOI . DOI \u00b6 In computing, a Digital Object Identifier or DOI is a persistent identifier or handle used to uniquely identify objects [..] A DOI aims to be \"resolvable\", usually to some form of access to the information object to which the DOI refers. via Wikipedia , see also https://doi.org ERC \u00b6 Executable Research Compendium, see this scientific article for concepts and the specification for technical documentation. Executable Research Compendium \u00b6 See ERC . JavaScript Promises \u00b6 A Promise is an object representing the eventual completion or failure of an asynchronous operation. [...] Essentially, a promise is a returned object to which you attach callbacks, instead of passing callbacks into a function. via MDN web docs Kernel \u00b6 The kernel is a computer program that is the core of a computer's operating system, with complete control over everything in the system. via Wikipedia A common example is the Linux kernel . Literate Programming \u00b6 Literate programming is a programming paradigm [..] in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated. via Wikipedia","title":"Glossary"},{"location":"glossary/#glossary","text":"","title":"Glossary"},{"location":"glossary/#architecture","text":"See computer architecture .","title":"Architecture"},{"location":"glossary/#computer-architecture","text":"[C]omputer architecture is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. Some definitions of architecture define it as describing the capabilities and programming model of a computer but not a particular implementation. In other definitions computer architecture involves instruction set architecture design, microarchitecture design, logic design, and implementation. via Wikipedia Common architectures are amd64 or x86_64 . You can find out the operating system + architecture combinations supported by a specific Docker image, e.g. golang , with $ docker run mplatform/mquery golang Image: golang * Manifest List: Yes * Supported platforms: - linux/amd64 - linux/arm/v7 - linux/arm64/v8 - linux/386 - linux/ppc64le - linux/s390x - windows/amd64:10.0.14393.2068 - windows/amd64:10.0.16299.248","title":"Computer Architecture"},{"location":"glossary/#crud","text":"Basic operations on a digital artefact are create, read, update, and delete, often abbreviated to \" CRUD \".","title":"CRUD"},{"location":"glossary/#digital-object-identifier","text":"See DOI .","title":"Digital Object Identifier"},{"location":"glossary/#doi","text":"In computing, a Digital Object Identifier or DOI is a persistent identifier or handle used to uniquely identify objects [..] A DOI aims to be \"resolvable\", usually to some form of access to the information object to which the DOI refers. via Wikipedia , see also https://doi.org","title":"DOI"},{"location":"glossary/#erc","text":"Executable Research Compendium, see this scientific article for concepts and the specification for technical documentation.","title":"ERC"},{"location":"glossary/#executable-research-compendium","text":"See ERC .","title":"Executable Research Compendium"},{"location":"glossary/#javascript-promises","text":"A Promise is an object representing the eventual completion or failure of an asynchronous operation. [...] Essentially, a promise is a returned object to which you attach callbacks, instead of passing callbacks into a function. via MDN web docs","title":"JavaScript Promises"},{"location":"glossary/#kernel","text":"The kernel is a computer program that is the core of a computer's operating system, with complete control over everything in the system. via Wikipedia A common example is the Linux kernel .","title":"Kernel"},{"location":"glossary/#literate-programming","text":"Literate programming is a programming paradigm [..] in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated. via Wikipedia","title":"Literate Programming"},{"location":"metadata/","text":"Metadata workflows \u00b6 This document describes the internal processes handling metadata for ERC. For information on the metadata model for ERC as part of the o2r web API please see the API specification . The remainder of this document describes who handles metadata when and how within the o2r architecture . Files vs. database \u00b6 In all workflows files are created within ERC in a specific subdirectory .erc holding different kinds, formats, or versions of metadata. For ease of access via web API, the information is also stored within the database. The files in the compendium are always the normative source of information. The term brokering means the translation from schema-less to schema-specific metadata, as well as inter-schema mappings. The brokering output is then stored in respective files and mirrored to the database by the reproducibility service. Metadata extraction and brokering during creation \u00b6 muncher is the main CRUD component for compedia. It controls the creation workflow. The creation from the metadata perspective is as follows: init stores the files for a new ERC in a directory. extract uses metaextract.py ( docs ) to analyse the incoming ERC and creates new files with raw metadata for each of the scanned files. Currently the following types of files will be considered: .r, .rmd, netcdf, \"bagit.txt\" . Future releases of the extractor will be likely to consider .tex, .json (geojson), .jp2, .tiff and more. This raw metadata itself is schema-less and non-semantic. The processed files are in conceptual competition for the best representative of the working directory's meta information, i.e. there will be only one main output, ideally represented by the most complete set of metadata. By default the competing bits of information will also be preserved in .erc/metadata_raw_<filename>.json where filename is an identifier based on the original source file. output file: .erc/metadata_raw.json database field: <compendium>.metadata.raw broker uses metabroker.py ( docs ) to translate the raw metadata in json to o2r metadata in json as being compliant to the o2r json-schema. - output file: .erc/metadata_o2r_X.json (where X is the version number as set in the o2r-map.json mapping file, e.g. 1 ) - database field: <compendium>.metadata.o2r ( harvest TBD; will connect to third party database endpoint via OAI-PMH to gather additional information for the enrichment of the o2r metadata collected via extraction) save stores the new ERC to the database including the aforementioned metadata fields. user check provides an interactive form to the uploading user to control and edit the suggested metadata. Suggestions are based on o2r metadata. The check workflow is handled in the web client project. update updates the metadata in both database and file with the user's edits. This step creates valid o2r metadata. The metadata update includes all brokering to the configured metadata formats, meaning the brokered metadata is always up-to-date and based on the same source, the o2r metadata. By design there is no metadata brokering during shipments or job executions. Because it is likely that not all information can be brokered automatically, the metadata required by shipping destinations are mandatory in the o2r metadata model to reduce the user involvement to a minimum, i.e. when updating the metadata. In the same vein, all validation takes place during metadata updates, because that is the only time a user can react to validation errors. Metadata for shipments \u00b6 The shipper uses the metadata stored in the ERC directory .erc to start a shipment of data or metadata to third-party repositories. It does not do any updating, brokering, or validation. Metadata mappings \u00b6 destination model format(s) description [//]: # ( datacite DataCite Metadata Schema 4.1 xml for metadata export) [//]: # ( datacite DataCite Metadata Schema 3.1 xml (still in wide spread use for OAI-PMH)) [//]: # ( ORCID (TBD) XML for orcid-works xml for adding ERC as works to an ORCID profile) [//]: # ( CRIS (TBD) (local adaptation of the CERIF model xml ...) b2share using o2r schema for the o2r community depositions on b2share json ... codemeta codemeta 2.0-rc json ld ... zenodo Deposition metadata json for storing full ERC in the Zenodo data repository; Zenodo also publishes metadata on DataCite","title":"Metadata"},{"location":"metadata/#metadata-workflows","text":"This document describes the internal processes handling metadata for ERC. For information on the metadata model for ERC as part of the o2r web API please see the API specification . The remainder of this document describes who handles metadata when and how within the o2r architecture .","title":"Metadata workflows"},{"location":"metadata/#files-vs-database","text":"In all workflows files are created within ERC in a specific subdirectory .erc holding different kinds, formats, or versions of metadata. For ease of access via web API, the information is also stored within the database. The files in the compendium are always the normative source of information. The term brokering means the translation from schema-less to schema-specific metadata, as well as inter-schema mappings. The brokering output is then stored in respective files and mirrored to the database by the reproducibility service.","title":"Files vs. database"},{"location":"metadata/#metadata-extraction-and-brokering-during-creation","text":"muncher is the main CRUD component for compedia. It controls the creation workflow. The creation from the metadata perspective is as follows: init stores the files for a new ERC in a directory. extract uses metaextract.py ( docs ) to analyse the incoming ERC and creates new files with raw metadata for each of the scanned files. Currently the following types of files will be considered: .r, .rmd, netcdf, \"bagit.txt\" . Future releases of the extractor will be likely to consider .tex, .json (geojson), .jp2, .tiff and more. This raw metadata itself is schema-less and non-semantic. The processed files are in conceptual competition for the best representative of the working directory's meta information, i.e. there will be only one main output, ideally represented by the most complete set of metadata. By default the competing bits of information will also be preserved in .erc/metadata_raw_<filename>.json where filename is an identifier based on the original source file. output file: .erc/metadata_raw.json database field: <compendium>.metadata.raw broker uses metabroker.py ( docs ) to translate the raw metadata in json to o2r metadata in json as being compliant to the o2r json-schema. - output file: .erc/metadata_o2r_X.json (where X is the version number as set in the o2r-map.json mapping file, e.g. 1 ) - database field: <compendium>.metadata.o2r ( harvest TBD; will connect to third party database endpoint via OAI-PMH to gather additional information for the enrichment of the o2r metadata collected via extraction) save stores the new ERC to the database including the aforementioned metadata fields. user check provides an interactive form to the uploading user to control and edit the suggested metadata. Suggestions are based on o2r metadata. The check workflow is handled in the web client project. update updates the metadata in both database and file with the user's edits. This step creates valid o2r metadata. The metadata update includes all brokering to the configured metadata formats, meaning the brokered metadata is always up-to-date and based on the same source, the o2r metadata. By design there is no metadata brokering during shipments or job executions. Because it is likely that not all information can be brokered automatically, the metadata required by shipping destinations are mandatory in the o2r metadata model to reduce the user involvement to a minimum, i.e. when updating the metadata. In the same vein, all validation takes place during metadata updates, because that is the only time a user can react to validation errors.","title":"Metadata extraction and brokering during creation"},{"location":"metadata/#metadata-for-shipments","text":"The shipper uses the metadata stored in the ERC directory .erc to start a shipment of data or metadata to third-party repositories. It does not do any updating, brokering, or validation.","title":"Metadata for shipments"},{"location":"metadata/#metadata-mappings","text":"destination model format(s) description [//]: # ( datacite DataCite Metadata Schema 4.1 xml for metadata export) [//]: # ( datacite DataCite Metadata Schema 3.1 xml (still in wide spread use for OAI-PMH)) [//]: # ( ORCID (TBD) XML for orcid-works xml for adding ERC as works to an ORCID profile) [//]: # ( CRIS (TBD) (local adaptation of the CERIF model xml ...) b2share using o2r schema for the o2r community depositions on b2share json ... codemeta codemeta 2.0-rc json ld ... zenodo Deposition metadata json for storing full ERC in the Zenodo data repository; Zenodo also publishes metadata on DataCite","title":"Metadata mappings"},{"location":"user-scenarios/","text":"User scenarios \u00b6 Andrea the author and reader \u00b6 Andrea turned 29 this year. She is always up for a joke and a pot of coffee but is also quite impatient. Especially if she has to wait for others or if she hasn\u2019t had any progress for a while. However, currently Andrea does her Ph.D in the field of geosciences. Two years ago she decided to go for a cumulative dissertation, meaning she publishes scientific papers throughout his graduation and summarizes them at the end. She already published his first paper a few months ago which is good, actually. One of the reviewers was interested in the data and the source-code in order to reproduce the results. After a few hours of searching (remember she is not one of the most patient), she finally finds some files which include the dataset and also the source-code in R (a statistics program). Just a short try if it still working... weird, the results are different. Just a short look into the paper... The configuration is different than the one described in the method section. Well, just few manipulations and - still not working. Although she submitted the paper just a few months ago, she can\u2019t remember the exact configuration for the results in the paper. Fortunately, submitting data and code was not mandatory. But Andrea knows she made a mistake. More and more journals expect their authors to submit data and source-code which underlie the research findings. For this reason, she wants to change her working behavior and to keep data and code files better under control. She remembers her last research work which was quite unstructured, maybe already messy. Code and data was distributed over several folders and even computers. She had so search for them for quite a while. Moreover, some components do not work anymore. This time, she wants to do it better and searches for a great tool assisting her workflow. She just heard about a new website supporting reproducible research. It allows to upload all necessary files and to create a so called \"container\" which is \"executable\" - whatever that means. It even verifies the results in the paper making it possible to detect errors immediately. Of course it also contains common features like sharing the publication with other authors. On top of that, Andrea can also benefit from other publications. As the website automatically generates a number of meta information, new search capabilities arise. It is not only possible to search for other publications by using keywords, but also by using spatial and temporal properties and constraints. It is even possible to constrain the search to hypotheses and research questions having certain vocabulary, thus simplifying search for related work. Andrea is quite impressed! She easily finds related papers around her own work. She gets a good overview about existing research questions making it easier to identify a research gap she can focus on. Andrea doesn\u2019t even have to implement all the code lines for her statistical analysis from scratch, but can build upon existing. While reading some of the related papers in the browser, she realizes a couple of user interface widgets besides the incorporated figures. He doesn\u2019t know them from traditional, static papers which are typically published as .pdf-files. Andrea recognizes that the widgets allow to interact with the diagrams to which the widgets belong. They allow to change, for example, thresholds, input variables and constants. She is thus able to check the assumptions and conclusions underlying the paper. She is a bit overwhelmed by the number of new features, such as exchanging the dataset or the source-code underlying the paper. Andrea is quite happy about her new tool. It provides support for structured work, finding related publications, algorithms and datasets, identifying a research gap, and even tools for interacting with traditional, static papers. So, let\u2019s go for the second paper. Arthur the administrator \u00b6 Arthur works as a system administrator in a large university library in Germany. He's quite happy with his job. After working as freelance software developer for over 20 years, he now enjoys the challenge to make all the different servers and applications under his care work like a charm 24/7 while having a stable paycheck and reasonable working hours. He is particularly proud that, since he took over the job, he successfully migrated all services to a private cloud infrastructure and enabled https-only traffic on all, event the internal, APIs and websites. Since then, there has been minimal overtime for him and close to 0 minutes downtime for the services... and a raise! Arthur is interested in this new reproducibility service which the head of the library is interested in, but he is sceptical about all new systems. There are going to be bugs, unforseen problems, and a lot of testing \"\"in production\"\", which he does not like. But he knows scientists have been in touch with the library before about archiving data and software, so if this is a high priority for his customers, as he sees them, there is no way around it. At second look though, he realizes the project seems to have all the basics straight for a stable and scalable deployment: All components are published under open source licenses, and the project maintainers provide different ready-to-use Docker images. Arthur worries about security, so there is no better way to make sure things work well than source code access. The project is written in a language he has not used before himself, but he can actually build the project himself from source with the provided instructions. He also understands that, instead of reinventing the wheel, the developers seem to be competent enough to build upon established libraries. The Dockerfiles are great to play around with, but also easy to integrate in his own server management solution. He also likes the HTTP APIs and the setup and configuration, which seem to be very well documented. This should make it easy to integrate the new solution with some custom tools he developed, but also with some legacy infrastructure he has not yet been able to get rid off. He does worry a bit about the scheduling solution, since he is not very keen on Docker containers being started automatically on his servers. Good thing the project contributors seem to operate a public chat, and professional support is also available at reasonable prices. After some testing, he feels good to tell his colleagues: looks good to me, let's try this out! Olivia the operator \u00b6 Olivia is the chancellor of a mid-size state owned university in the US. She is proud to have been elected to this position a few years ago, and works very hard each day to improve both the university's reputation and the working and learning conditions of her employees and students. She had to make some unpleasant first hand experiences with aspects of todays academic life, some of which sadly became almost normal: budget cuts, violence on campus, and plagiarism scandals. During all of these upsets, she is happy she never wavered on the importance of personal integrity and credibility of each and every one of the scientists and researchers working on her campus. To gain some ground in the competition with other universities, Olivia puts her best assistant on the job of finding the newest trends in academia. Soon enough she presents to her the idea of making all research conducted at the university reproducible. Olivia is first surprised by the fact, being an arts major herself, as she thought that is already the case. She starts reading the material provided to hear and realizes science, and especially something called computational science, is very much different from the practical work she has encountered during her years as a researcher. It also becomes clear it won't work to just put out a statement forcing every lab to spend enormous efforts on changing established research practices, or to re-do what has been done 5, 10 or 20 years ago. The huge variety of labs and workflows and all the different kinds of people... getting out the stick simply won't work. But maybe the carrot will? She discovers a novel website. It promises to solve all the problems of reproducibility. The people behind it seem competent enough to her, but again she asks her assistant to consult with experts from the university library and computer science departments to see what they think. A lengthy discussion starts, and there seems to be no consensus after months of meetings and evaluations. The assistant doesn't know what to report back to Olivia. Eventually, Olivia is tired of waiting and joins a few of the meetings of the expert group as an observer. She realizes nothing comes for free... she encourages the expert group to create a list of requirements on establishing a reproducibility website for the university. She quickly understands they might get the proper time and money to do it, because the lecturers and staff in the group realize they won't just get more work to do! Olivia makes the new website a matter for the boss. She successfully acquires the funds to start and maintain both the technical services and to hire support staff to maintain it. Beyond that, the supports staff is even equipped to provided consultancy services to all researchers at the university. These services quickly become popular across all disciplines working with data and code, and after just a few months, more and more fully reproducible papers appear on the public reproducibility website. Olivia is very glad to see the changes she introduced did not have an impact on the scientific output of the university - the monthly statistics tell her that much. Is the quality or quantity of the output going to increase? It's too soon to tell, but Olivia is sure it will. Just last week, the head of the programme reported to her that now ten papers are available on the website for which researchers from different university departments collaborated, who never collaborated before - they discovered the overlap through the new system! More than 20 undergraduate courses teaching scientific methods incorporated material from the website into their course schedule, and 50% of the graduate theses from the computer science department are now using the university reproducibility tools. Those are good enough signs for Olivia. She decides to pitch an idea to the university board: let's include reproducibility of publications as an evaluation factor for the budget allocations next year. You got to use the stick from time to time to make people appreciate the carrot. Carl the curator \u00b6 Carl works as a digital assets curator at a university library in Germany. He has been working as a librarian for about ten years and experienced the digital transformation of the field, which is why he specialized in the area of digital curation and archiving. He is qualified to manage and organize several collections of digital objects at a given time and recently selected objects for an exhibition of gold standard open access publications in the software category of his institutions catalog front page. Carl\u2019s expertise encompasses the management of accessibility levels as well as the preservation of file integrity and meta data curation. Since he discovered a growing interest in the preservation of software, he realized reproducibility of research findings, including code and data increases the value and visibility of his university\u2019s portfolio. As a result, Carl is working closely with the library\u2019s team for Research Data Management, in order to facilitate integration of reproducible computational environments into the digital objects' life cycle. This work matches their current policies. As he strongly believes publicly funded research data are public goods, Carl values his profession as a vital point of intersection between researchers, librarians und the general public. Therefore, when planning a selection of digital assets or curating the library\u2019s catalogs, Carl enjoys the interoperability provided by international metadata standards and linked open data vocabularies. Polly the publisher \u00b6 Polly is the head of a large publishing firm for scientific journals. She grew up being part of a publisher family, the third of four kids. While her older brothers wrestled with the family legacy, she has always been close to her late grandfather, who started the publishing business as a young man. So it came as no surprise she studied arts and library science and after a few well planned career steps around the globe, she joined the family business as assistant of her father and became CEO after a few years, a decision she rarely regrets. Though there is one thing making her job challenging every day: technology's high development speed. For a large publishing business, it is hard to keep up with new and modern technology. She has to serve both old (in more than one way) customers and employers, who have had a long relationship and a work environment and processes which have developed and settled in over many years. On the other hand, she sees new ideas by entrepreneurs and startups almost every week, some crazy and some rightfully called revolutionary, who experiment with new ways to publish science without the baggage of a reputation and hundreds of journals and an order of magnitude more employees. So what should Polly do? Scramble up some money to acquire a few startups and replace the existing review and authoring solution? Fire all staff members who are too slow adopting the new technologies? Close journals with an excellent reputation because editors and reviewers are not tech-savvy? Obviously, none of these were an option. Change had to come gradually and inclusively, not in a disruptive fashion. Polly turned to her CTO Charlotte. She joined the company recently and played out to be a very good hire, as she was able to revive the in-house development team with a positive attitude and a few key hires. Charlotte is aware of the challenges and agrees to compile an action plan from her perspective. A few weeks later, she presents the options to Polly and the other board members. She suggests to adopt an open service for interactive publications, which is an integrated solution for hosting and archiving data as well as code, all of which are often part of publications these days. It is open source, but of course it does not come for free. Charlotte suggests a combined approach of experiments by her own staff and external consulting by the original developers of the software. And she quickly mitigates all concerns raised by the other CxOs: the website is customizable, so it will not look like the competitors versions, it is extensible, so their few \"cool features\" which have been developed over the last years will be easy to integrate, and it is compatible with the existing data repository (so no need to replace that beast of a software). This new website would be an option presented to all editors to adopt for their journals. Education of the company's staff would precede this offer to make sure the intended message is spread: don't be left behind, challenge reviewers and authors to improve the quality of the journals and subsequently raise the bar for high quality open science. Richard the reviewer \u00b6 Richard is a successful researcher. After getting tenure a few years back, he embraces the chance to support students and collaborate with other scientists instead of hunting for the next easy publication to get his name on. A big part of his time is taken up by his membership in the editorial boards of two journals and his engagement with several more journals as a reviewer. Richard is \"senior\" in some ways, and he as well as his colleagues know his value lies in experience, not in hunting the latest hot new things. Therefore Richard never came around to catch up practically with the latest technologies, and while he has a good understanding of computer science and used to be a very capable programmer, this new stuff the kids are doing is beyond his means. As the next paper review request lands in his inbox, he skims the abstract and soon thinks \"I will never be able to thoroughly evaluate this work, the code must be too complex to run on my machine\". But the content is so interesting! What a shame. He almost replies with a negative answer and then sees a new link at the bottom of the notification. The publisher must have added a new feature. The link's title is \"Click here to examine and manipulate code and data\". Richard clicks the link. He is taken to a website looking partially similar to the old review system he is used to. One the one side there is the well-known article view where he can read, add highlights and make comments. But on the other side, there is a new menu he enthusiastically explores. It allows him to edit parameters and re-run analysis of the paper! Without even downloading any data or code. He immediately sees the benefits: What a relief for his work, and what a chance to dig deeper into the article and conduct a thorough review. After some brief inspections of the article figures and manipulation of some parameters, Richard feels confident he can actually do the review properly. He let's the editor know about his decision and wants to dive right back into the article, but then stops himself. First, he writes an email to his fellow editors about this new review system for evaluating code and data - they need it for their journal, too. Rachel the reader \u00b6 Rachel is a second year graduate student in geoinformatics. She's eager to learn and has left all struggles with the technical side of research, and has become a trusted programmer in her group and is seen as an expert in more than one programming language. When she starts one of her final courses in advanced geoinformatics, the lecturer sends out a long list of reading material. How is she supposed to get through all of it? Never faltering, she starts reading all the documents... After the third article, she is annoyed and underwhelmed by the fancy descriptions and high-level diagrams. Although they all make sense, she feels like there is more to see and understand than is presented in the article. She shares her thoughts with her teacher Teresa during the next seminar. Teresa can relate to Rachel's frustration and quickly points her to items 8 and 9 on the reading list. \"These are different\", she says. Rachel gets back to reading. The next articles start out the same as the others, but she soon realizes something is different. The website takes a bit longer to load, and the graphics do not seem like they are compressed images at all. She needs some time to explore the relatively complex navigation, but then is excited to discover she can read and even download all the code and data which was used to generate the figures. Even more, she can interact with the present methods and play around with the algorithms. Finally she can immediately test her own understanding, challenge her criticism, and resolve misunderstandings. She plays around with the articles on the website for a little while and spends a lot longer on trying to understand the bits and pieces. Eventually she sees a close relation of one aspect of the analysis with the research project she though about doing for her thesis. Rachel is enthusiastic and directly downloads the whole article with its code to her own laptop to try the code out with her own dataset.","title":"User scenarios"},{"location":"user-scenarios/#user-scenarios","text":"","title":"User scenarios"},{"location":"user-scenarios/#andrea-the-author-and-reader","text":"Andrea turned 29 this year. She is always up for a joke and a pot of coffee but is also quite impatient. Especially if she has to wait for others or if she hasn\u2019t had any progress for a while. However, currently Andrea does her Ph.D in the field of geosciences. Two years ago she decided to go for a cumulative dissertation, meaning she publishes scientific papers throughout his graduation and summarizes them at the end. She already published his first paper a few months ago which is good, actually. One of the reviewers was interested in the data and the source-code in order to reproduce the results. After a few hours of searching (remember she is not one of the most patient), she finally finds some files which include the dataset and also the source-code in R (a statistics program). Just a short try if it still working... weird, the results are different. Just a short look into the paper... The configuration is different than the one described in the method section. Well, just few manipulations and - still not working. Although she submitted the paper just a few months ago, she can\u2019t remember the exact configuration for the results in the paper. Fortunately, submitting data and code was not mandatory. But Andrea knows she made a mistake. More and more journals expect their authors to submit data and source-code which underlie the research findings. For this reason, she wants to change her working behavior and to keep data and code files better under control. She remembers her last research work which was quite unstructured, maybe already messy. Code and data was distributed over several folders and even computers. She had so search for them for quite a while. Moreover, some components do not work anymore. This time, she wants to do it better and searches for a great tool assisting her workflow. She just heard about a new website supporting reproducible research. It allows to upload all necessary files and to create a so called \"container\" which is \"executable\" - whatever that means. It even verifies the results in the paper making it possible to detect errors immediately. Of course it also contains common features like sharing the publication with other authors. On top of that, Andrea can also benefit from other publications. As the website automatically generates a number of meta information, new search capabilities arise. It is not only possible to search for other publications by using keywords, but also by using spatial and temporal properties and constraints. It is even possible to constrain the search to hypotheses and research questions having certain vocabulary, thus simplifying search for related work. Andrea is quite impressed! She easily finds related papers around her own work. She gets a good overview about existing research questions making it easier to identify a research gap she can focus on. Andrea doesn\u2019t even have to implement all the code lines for her statistical analysis from scratch, but can build upon existing. While reading some of the related papers in the browser, she realizes a couple of user interface widgets besides the incorporated figures. He doesn\u2019t know them from traditional, static papers which are typically published as .pdf-files. Andrea recognizes that the widgets allow to interact with the diagrams to which the widgets belong. They allow to change, for example, thresholds, input variables and constants. She is thus able to check the assumptions and conclusions underlying the paper. She is a bit overwhelmed by the number of new features, such as exchanging the dataset or the source-code underlying the paper. Andrea is quite happy about her new tool. It provides support for structured work, finding related publications, algorithms and datasets, identifying a research gap, and even tools for interacting with traditional, static papers. So, let\u2019s go for the second paper.","title":"Andrea the author and reader"},{"location":"user-scenarios/#arthur-the-administrator","text":"Arthur works as a system administrator in a large university library in Germany. He's quite happy with his job. After working as freelance software developer for over 20 years, he now enjoys the challenge to make all the different servers and applications under his care work like a charm 24/7 while having a stable paycheck and reasonable working hours. He is particularly proud that, since he took over the job, he successfully migrated all services to a private cloud infrastructure and enabled https-only traffic on all, event the internal, APIs and websites. Since then, there has been minimal overtime for him and close to 0 minutes downtime for the services... and a raise! Arthur is interested in this new reproducibility service which the head of the library is interested in, but he is sceptical about all new systems. There are going to be bugs, unforseen problems, and a lot of testing \"\"in production\"\", which he does not like. But he knows scientists have been in touch with the library before about archiving data and software, so if this is a high priority for his customers, as he sees them, there is no way around it. At second look though, he realizes the project seems to have all the basics straight for a stable and scalable deployment: All components are published under open source licenses, and the project maintainers provide different ready-to-use Docker images. Arthur worries about security, so there is no better way to make sure things work well than source code access. The project is written in a language he has not used before himself, but he can actually build the project himself from source with the provided instructions. He also understands that, instead of reinventing the wheel, the developers seem to be competent enough to build upon established libraries. The Dockerfiles are great to play around with, but also easy to integrate in his own server management solution. He also likes the HTTP APIs and the setup and configuration, which seem to be very well documented. This should make it easy to integrate the new solution with some custom tools he developed, but also with some legacy infrastructure he has not yet been able to get rid off. He does worry a bit about the scheduling solution, since he is not very keen on Docker containers being started automatically on his servers. Good thing the project contributors seem to operate a public chat, and professional support is also available at reasonable prices. After some testing, he feels good to tell his colleagues: looks good to me, let's try this out!","title":"Arthur the administrator"},{"location":"user-scenarios/#olivia-the-operator","text":"Olivia is the chancellor of a mid-size state owned university in the US. She is proud to have been elected to this position a few years ago, and works very hard each day to improve both the university's reputation and the working and learning conditions of her employees and students. She had to make some unpleasant first hand experiences with aspects of todays academic life, some of which sadly became almost normal: budget cuts, violence on campus, and plagiarism scandals. During all of these upsets, she is happy she never wavered on the importance of personal integrity and credibility of each and every one of the scientists and researchers working on her campus. To gain some ground in the competition with other universities, Olivia puts her best assistant on the job of finding the newest trends in academia. Soon enough she presents to her the idea of making all research conducted at the university reproducible. Olivia is first surprised by the fact, being an arts major herself, as she thought that is already the case. She starts reading the material provided to hear and realizes science, and especially something called computational science, is very much different from the practical work she has encountered during her years as a researcher. It also becomes clear it won't work to just put out a statement forcing every lab to spend enormous efforts on changing established research practices, or to re-do what has been done 5, 10 or 20 years ago. The huge variety of labs and workflows and all the different kinds of people... getting out the stick simply won't work. But maybe the carrot will? She discovers a novel website. It promises to solve all the problems of reproducibility. The people behind it seem competent enough to her, but again she asks her assistant to consult with experts from the university library and computer science departments to see what they think. A lengthy discussion starts, and there seems to be no consensus after months of meetings and evaluations. The assistant doesn't know what to report back to Olivia. Eventually, Olivia is tired of waiting and joins a few of the meetings of the expert group as an observer. She realizes nothing comes for free... she encourages the expert group to create a list of requirements on establishing a reproducibility website for the university. She quickly understands they might get the proper time and money to do it, because the lecturers and staff in the group realize they won't just get more work to do! Olivia makes the new website a matter for the boss. She successfully acquires the funds to start and maintain both the technical services and to hire support staff to maintain it. Beyond that, the supports staff is even equipped to provided consultancy services to all researchers at the university. These services quickly become popular across all disciplines working with data and code, and after just a few months, more and more fully reproducible papers appear on the public reproducibility website. Olivia is very glad to see the changes she introduced did not have an impact on the scientific output of the university - the monthly statistics tell her that much. Is the quality or quantity of the output going to increase? It's too soon to tell, but Olivia is sure it will. Just last week, the head of the programme reported to her that now ten papers are available on the website for which researchers from different university departments collaborated, who never collaborated before - they discovered the overlap through the new system! More than 20 undergraduate courses teaching scientific methods incorporated material from the website into their course schedule, and 50% of the graduate theses from the computer science department are now using the university reproducibility tools. Those are good enough signs for Olivia. She decides to pitch an idea to the university board: let's include reproducibility of publications as an evaluation factor for the budget allocations next year. You got to use the stick from time to time to make people appreciate the carrot.","title":"Olivia the operator"},{"location":"user-scenarios/#carl-the-curator","text":"Carl works as a digital assets curator at a university library in Germany. He has been working as a librarian for about ten years and experienced the digital transformation of the field, which is why he specialized in the area of digital curation and archiving. He is qualified to manage and organize several collections of digital objects at a given time and recently selected objects for an exhibition of gold standard open access publications in the software category of his institutions catalog front page. Carl\u2019s expertise encompasses the management of accessibility levels as well as the preservation of file integrity and meta data curation. Since he discovered a growing interest in the preservation of software, he realized reproducibility of research findings, including code and data increases the value and visibility of his university\u2019s portfolio. As a result, Carl is working closely with the library\u2019s team for Research Data Management, in order to facilitate integration of reproducible computational environments into the digital objects' life cycle. This work matches their current policies. As he strongly believes publicly funded research data are public goods, Carl values his profession as a vital point of intersection between researchers, librarians und the general public. Therefore, when planning a selection of digital assets or curating the library\u2019s catalogs, Carl enjoys the interoperability provided by international metadata standards and linked open data vocabularies.","title":"Carl the curator"},{"location":"user-scenarios/#polly-the-publisher","text":"Polly is the head of a large publishing firm for scientific journals. She grew up being part of a publisher family, the third of four kids. While her older brothers wrestled with the family legacy, she has always been close to her late grandfather, who started the publishing business as a young man. So it came as no surprise she studied arts and library science and after a few well planned career steps around the globe, she joined the family business as assistant of her father and became CEO after a few years, a decision she rarely regrets. Though there is one thing making her job challenging every day: technology's high development speed. For a large publishing business, it is hard to keep up with new and modern technology. She has to serve both old (in more than one way) customers and employers, who have had a long relationship and a work environment and processes which have developed and settled in over many years. On the other hand, she sees new ideas by entrepreneurs and startups almost every week, some crazy and some rightfully called revolutionary, who experiment with new ways to publish science without the baggage of a reputation and hundreds of journals and an order of magnitude more employees. So what should Polly do? Scramble up some money to acquire a few startups and replace the existing review and authoring solution? Fire all staff members who are too slow adopting the new technologies? Close journals with an excellent reputation because editors and reviewers are not tech-savvy? Obviously, none of these were an option. Change had to come gradually and inclusively, not in a disruptive fashion. Polly turned to her CTO Charlotte. She joined the company recently and played out to be a very good hire, as she was able to revive the in-house development team with a positive attitude and a few key hires. Charlotte is aware of the challenges and agrees to compile an action plan from her perspective. A few weeks later, she presents the options to Polly and the other board members. She suggests to adopt an open service for interactive publications, which is an integrated solution for hosting and archiving data as well as code, all of which are often part of publications these days. It is open source, but of course it does not come for free. Charlotte suggests a combined approach of experiments by her own staff and external consulting by the original developers of the software. And she quickly mitigates all concerns raised by the other CxOs: the website is customizable, so it will not look like the competitors versions, it is extensible, so their few \"cool features\" which have been developed over the last years will be easy to integrate, and it is compatible with the existing data repository (so no need to replace that beast of a software). This new website would be an option presented to all editors to adopt for their journals. Education of the company's staff would precede this offer to make sure the intended message is spread: don't be left behind, challenge reviewers and authors to improve the quality of the journals and subsequently raise the bar for high quality open science.","title":"Polly the publisher"},{"location":"user-scenarios/#richard-the-reviewer","text":"Richard is a successful researcher. After getting tenure a few years back, he embraces the chance to support students and collaborate with other scientists instead of hunting for the next easy publication to get his name on. A big part of his time is taken up by his membership in the editorial boards of two journals and his engagement with several more journals as a reviewer. Richard is \"senior\" in some ways, and he as well as his colleagues know his value lies in experience, not in hunting the latest hot new things. Therefore Richard never came around to catch up practically with the latest technologies, and while he has a good understanding of computer science and used to be a very capable programmer, this new stuff the kids are doing is beyond his means. As the next paper review request lands in his inbox, he skims the abstract and soon thinks \"I will never be able to thoroughly evaluate this work, the code must be too complex to run on my machine\". But the content is so interesting! What a shame. He almost replies with a negative answer and then sees a new link at the bottom of the notification. The publisher must have added a new feature. The link's title is \"Click here to examine and manipulate code and data\". Richard clicks the link. He is taken to a website looking partially similar to the old review system he is used to. One the one side there is the well-known article view where he can read, add highlights and make comments. But on the other side, there is a new menu he enthusiastically explores. It allows him to edit parameters and re-run analysis of the paper! Without even downloading any data or code. He immediately sees the benefits: What a relief for his work, and what a chance to dig deeper into the article and conduct a thorough review. After some brief inspections of the article figures and manipulation of some parameters, Richard feels confident he can actually do the review properly. He let's the editor know about his decision and wants to dive right back into the article, but then stops himself. First, he writes an email to his fellow editors about this new review system for evaluating code and data - they need it for their journal, too.","title":"Richard the reviewer"},{"location":"user-scenarios/#rachel-the-reader","text":"Rachel is a second year graduate student in geoinformatics. She's eager to learn and has left all struggles with the technical side of research, and has become a trusted programmer in her group and is seen as an expert in more than one programming language. When she starts one of her final courses in advanced geoinformatics, the lecturer sends out a long list of reading material. How is she supposed to get through all of it? Never faltering, she starts reading all the documents... After the third article, she is annoyed and underwhelmed by the fancy descriptions and high-level diagrams. Although they all make sense, she feels like there is more to see and understand than is presented in the article. She shares her thoughts with her teacher Teresa during the next seminar. Teresa can relate to Rachel's frustration and quickly points her to items 8 and 9 on the reading list. \"These are different\", she says. Rachel gets back to reading. The next articles start out the same as the others, but she soon realizes something is different. The website takes a bit longer to load, and the graphics do not seem like they are compressed images at all. She needs some time to explore the relatively complex navigation, but then is excited to discover she can read and even download all the code and data which was used to generate the figures. Even more, she can interact with the present methods and play around with the algorithms. Finally she can immediately test her own understanding, challenge her criticism, and resolve misunderstandings. She plays around with the articles on the website for a little while and spends a lot longer on trying to understand the bits and pieces. Eventually she sees a close relation of one aspect of the analysis with the research project she though about doing for her thesis. Rachel is enthusiastic and directly downloads the whole article with its code to her own laptop to try the code out with her own dataset.","title":"Rachel the reader"},{"location":"zenodo/","text":"Zenodo integration \u00b6 Zenodo, and other data repositories, provide a way to create a collection of records. At Zenodo these are called _communities. In the context of o2r, we have created a community o2r (also in the sandbox ). Issues There is no semi-automated workflow for adding a Zenodo record to a community A curation policy should guide the community management Workflow \u00b6 communities metadata element in Zenodo metadata can be used to trigger the workflow only: List of communities you wish the deposition to appear. The owner of the community will be notified, and can either accept or reject your request. Each array element is an object with the attributes: someone needs to curate and \"accept\" / \"approve\" ERCs as Zenodo records upon submission, there is no API function for that. UI integration Curation policy \u00b6 We need to write a policy for that community where all ERC are collected by default when shipped to Zenodo. They must be in line with http://about.zenodo.org/policies/ and http://about.zenodo.org/terms/. Content for the policy the records must be a valid ERC","title":"Zenodo integration"},{"location":"zenodo/#zenodo-integration","text":"Zenodo, and other data repositories, provide a way to create a collection of records. At Zenodo these are called _communities. In the context of o2r, we have created a community o2r (also in the sandbox ). Issues There is no semi-automated workflow for adding a Zenodo record to a community A curation policy should guide the community management","title":"Zenodo integration"},{"location":"zenodo/#workflow","text":"communities metadata element in Zenodo metadata can be used to trigger the workflow only: List of communities you wish the deposition to appear. The owner of the community will be notified, and can either accept or reject your request. Each array element is an object with the attributes: someone needs to curate and \"accept\" / \"approve\" ERCs as Zenodo records upon submission, there is no API function for that. UI integration","title":"Workflow"},{"location":"zenodo/#curation-policy","text":"We need to write a policy for that community where all ERC are collected by default when shipped to Zenodo. They must be in line with http://about.zenodo.org/policies/ and http://about.zenodo.org/terms/. Content for the policy the records must be a valid ERC","title":"Curation policy"}]}